{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0baead1d-7b40-405b-bb4a-7efb950c6157",
   "metadata": {},
   "source": [
    "First we instantiate the simulator class we will use to generate our sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a91ec2-b74f-4154-8844-19d876af75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.groundtruth import GroundTruthPath, GroundTruthState\n",
    "from stonesoup.types.detection import Detection\n",
    "\n",
    "from stonesoup.types.track import Track\n",
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "\n",
    "class simulator():\n",
    "\n",
    "    def __init__(self, transition_model, measurement_model):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_model : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        measurement_model : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        \"\"\"\n",
    "        self.transition_model= transition_model\n",
    "        self.measurement_model = measurement_model        \n",
    "    \n",
    "    def _generate_ground_truth(self, prior, time_span):\n",
    "        \n",
    "        time_interval = time_span[1]-time_span[0]\n",
    "        ground_truth = GroundTruthPath([prior])\n",
    "        for k in range(1, len(time_span)):\n",
    "            ground_truth.append(GroundTruthState(\n",
    "                self.transition_model.function(ground_truth[k-1], noise=False, time_interval=time_interval),\n",
    "                timestamp=time_span[k-1]))\n",
    "        return ground_truth\n",
    "    \n",
    "    def _simulate_measurements(self, ground_truth):\n",
    "        #Simulate Measurements\n",
    "        measurements = []\n",
    "        for state in ground_truth:\n",
    "            measurement = self.measurement_model.function(state, noise=True)\n",
    "            measurements.append(Detection(measurement,\n",
    "                                          timestamp=state.timestamp,\n",
    "                                          measurement_model=self.measurement_model))\n",
    "        return measurements\n",
    "    \n",
    "    def generate_training_data(self, initial_state, time_span):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ground_truth : :class:`~.GroundTruthPath`\n",
    "            StateMutableSequence type object used to store ground truth.\n",
    "        initial_state : :class:`~.State`\n",
    "            Initial state for the ground truth system. This MUST be a State,\n",
    "            not a State subclass, like GaussianState or EnsembleState.\n",
    "        prior : :class:`~.GaussianState` or :class:`~.EnsembleState`\n",
    "            Initial state prediction of tracking algorithm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        track : :class:`~.Track`\n",
    "            The Stone Soup track object which contains the list of updated \n",
    "            state predictions made by the tracking algorithm employed.\n",
    "        \"\"\"\n",
    "\n",
    "        #Simulate Measurements\n",
    "        ground_truth = self._generate_ground_truth(initial_state, time_span)\n",
    "        measurements = self._simulate_measurements(ground_truth)\n",
    "        \n",
    "        return ground_truth, measurements\n",
    "\n",
    "    def simulate_track(self, predictor, updater, initial_state, prior, time_span):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictor : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        updater : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        ground_truth : :class:`~.GroundTruthPath`\n",
    "            StateMutableSequence type object used to store ground truth.\n",
    "        initial_state : :class:`~.State`\n",
    "            Initial state for the ground truth system. This MUST be a State,\n",
    "            not a State subclass, like GaussianState or EnsembleState.\n",
    "        prior : :class:`~.GaussianState` or :class:`~.EnsembleState`\n",
    "            Initial state prediction of tracking algorithm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        track : :class:`~.Track`\n",
    "            The Stone Soup track object which contains the list of updated \n",
    "            state predictions made by the tracking algorithm employed.\n",
    "        \"\"\"\n",
    "\n",
    "        #Simulate Measurements\n",
    "        ground_truth = self._generate_ground_truth(initial_state, time_span)\n",
    "        measurements = self._simulate_measurements(ground_truth)\n",
    "        \n",
    "        #Initialize Loop Variables\n",
    "        track = Track()\n",
    "        for measurement in measurements:\n",
    "            prediction = predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "            hypothesis = SingleHypothesis(prediction, measurement)  # Group a prediction and measurement\n",
    "            posterior = updater.update(hypothesis)\n",
    "            track.append(posterior)\n",
    "            prior = track[-1]\n",
    "        return ground_truth, track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc4d79-f839-49f3-87f6-7ef115d95ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89b226e-0314-4d3b-ad70-5381641097e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: John Hiles\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "from stonesoup.types.array import StateVector, CovarianceMatrix\n",
    "from stonesoup.types.state import State, GaussianState, EnsembleState\n",
    "\n",
    "from stonesoup.models.transition.linear import (CombinedLinearGaussianTransitionModel,\n",
    "                                                ConstantVelocity)\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "from stonesoup.updater.ensemble import (EnsembleUpdater, EnsembleSqrtUpdater)\n",
    "from stonesoup.updater.kalman import KalmanUpdater, ExtendedKalmanUpdater\n",
    "from stonesoup.predictor.ensemble import EnsemblePredictor\n",
    "from stonesoup.predictor.kalman import KalmanPredictor, ExtendedKalmanPredictor\n",
    "from stonesoup.models.measurement.nonlinear import CartesianToBearingRange\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    This script represents the code used to gather the data used in [PAPER HERE].\n",
    "    \n",
    "    This repository is structured such that different stone soup algorithms \n",
    "    can be run rapidly. Hopefully I've made it modular enough to \n",
    "    allow swapping of things like algorithms, and \"experiments\" by replacing\n",
    "    the desired transition and measurement models.\n",
    "    \n",
    "    The simulator class requires a transition and \n",
    "    measurement model, then the simulate_track method accepts a Stone Soup\n",
    "    Predictor, Updater, ground truth initial state, initial state for the\n",
    "    chosen algorithm, and a span of time which the simulation takes place over.\n",
    "    This time span should be an evenly spaced datetime.datetime list.\n",
    "    \n",
    "    The simulator then, is used to gather \"Track\" instances, and with a list \n",
    "    of tracks, RMSE can then be calculated.\n",
    "\"\"\"\n",
    "\n",
    "i = 30\n",
    "num_vectors = i*5\n",
    "\n",
    "\"\"\"\n",
    "    Here, we get our initial variables for simulation. For this, we are just\n",
    "    using a time span of 60 time instances spaced one second apart.\n",
    "\"\"\"\n",
    "\n",
    "timestamp = datetime.datetime(2021, 4, 2, 12, 28, 57)\n",
    "tMax = 120\n",
    "dt = 1\n",
    "tRange = tMax // dt\n",
    "plot_time_span = np.array([dt*i for i in range(tRange)])\n",
    "\n",
    "time_span = np.array([timestamp + datetime.timedelta(seconds=dt*i) for i in range(tRange)])\n",
    "\n",
    "monte_carlo_iterations = 10\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Here we instantiate our transition and measurement models. These are the \n",
    "same models used in the StoneSoup Kalman Filter examples.\n",
    "\"\"\"\n",
    "\n",
    "q_x = 0.05\n",
    "q_y = 0.05\n",
    "sensor_x = 50  # Placing the sensor off-centre\n",
    "sensor_y = 0\n",
    "\n",
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(q_x), \n",
    "                                                          ConstantVelocity(q_y)])\n",
    "measurement_model = CartesianToBearingRange(\n",
    "ndim_state=4,\n",
    "mapping=(0, 2),\n",
    "noise_covar=np.diag([np.radians(0.2), 1]),  # Covariance matrix. 0.2 degree variance in\n",
    "# bearing and 1 metre in range\n",
    "translation_offset=np.array([[sensor_x], [sensor_y]])  # Offset measurements to location of\n",
    "# sensor in cartesian.\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Here we instantiate the simulator with our transition and measurement model.\n",
    "This class is capable of generating sets of ground truth points, and simulate\n",
    "measurements for our recursive filters.\n",
    "\"\"\"\n",
    "\n",
    "nonlinear_simulator = simulator(transition_model=transition_model,\n",
    "                      measurement_model=measurement_model)\n",
    "\n",
    "\"\"\"\n",
    "To get our data, we will run three simulations with varying values for \n",
    "num_vectors, which corresponds to M in our paper. The number of vectors in the\n",
    "ensemble.\n",
    "\n",
    "Structurally, we have two loops. The outer loop determines how many vectors\n",
    "are in our ensemble, the inner loop runs the simulation to gather the data.\n",
    "\"\"\"\n",
    "\n",
    "initial_ground_truth = State(state_vector=StateVector([0, 1, 0, 1]),\n",
    "                             timestamp = time_span[0])\n",
    "import torch\n",
    "\n",
    "ground_truth, measurements = nonlinear_simulator.generate_training_data(initial_ground_truth, time_span)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3c7b9-e997-4aab-a103-a504880da933",
   "metadata": {},
   "source": [
    "Now with our simulator we need to instantiate the Pytorch Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b76935-2e6b-46e2-9712-e3bb6fb1815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Datasets should be specified on a per simulation basis\n",
    "\n",
    "#class sequence_generator(Dataset):\n",
    "\n",
    "class dataset_2D_bearing_range(Dataset):\n",
    "    #Range Bearing 2D Dataset Sequence Packer\n",
    "\n",
    "    def __init__(self, dataset, ground_truth=None, measurements=None):\n",
    "        if dataset == None:   \n",
    "            gt = np.array([e.state_vector for e in ground_truth]).squeeze().T\n",
    "            gt = torch.tensor(gt.astype(dtype=np.float32),device = device)\n",
    "            ms = np.array([m.state_vector for m in measurements]).squeeze().T\n",
    "            ms = torch.tensor(ms.astype(dtype=np.float32),device = device)\n",
    "            self.dataset = torch.unsqueeze(torch.cat((gt,ms)),dim=0)\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "            \n",
    "    \n",
    "    def append_to_dataset(self, ground_truth, measurements):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ground_truth : :class:`~.list`\n",
    "            A list of Stonesoup States.\n",
    "        measurements : :class:`~.measurements`\n",
    "            The list of Stonesoup Measurements to be used.\n",
    "        \"\"\"\n",
    "    \n",
    "        gt = np.array([e.state_vector for e in ground_truth]).squeeze().T\n",
    "        gt = torch.tensor(gt.astype(dtype=np.float32),device = device)\n",
    "        ms = np.array([m.state_vector for m in measurements]).squeeze().T\n",
    "        ms = torch.tensor(ms.astype(dtype=np.float32),device = device)\n",
    "        new_entry = torch.cat((gt,ms),dim=0)\n",
    "\n",
    "        self.dataset = torch.cat((self.dataset,torch.unsqueeze(new_entry,dim=0)),dim=0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx,0:2].T, self.dataset[idx,0:4].T\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5f341-04aa-4f3f-b554-c01f40df6165",
   "metadata": {},
   "source": [
    "Now we need to simulate and add to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3514489-8f13-464a-8c87-296cb40cf9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "training_dataset =  dataset_2D_bearing_range(dataset = None, ground_truth = ground_truth, measurements = measurements)\n",
    "\n",
    "training_dataset_len = 1000\n",
    "\n",
    "for i in range(training_dataset_len-1):\n",
    "    ground_truth, measurements = nonlinear_simulator.generate_training_data(initial_ground_truth, time_span)\n",
    "    training_dataset.append_to_dataset(ground_truth, measurements)\n",
    "\n",
    "print(training_dataset.__len__())\n",
    "#print(training_dataset.__getitem__(2)[0].shape)\n",
    "#print(training_dataset.__getitem__(2)[1].shape)\n",
    "\n",
    "trainloader = DataLoader(training_dataset)\n",
    "\n",
    "testing_dataset =  dataset_2D_bearing_range(dataset = None, ground_truth = ground_truth, measurements = measurements)\n",
    "for i in range(int((training_dataset_len)/4 -1)):\n",
    "    ground_truth, measurements = nonlinear_simulator.generate_training_data(initial_ground_truth, time_span)\n",
    "    testing_dataset.append_to_dataset(ground_truth, measurements)\n",
    "testloader = DataLoader(testing_dataset)\n",
    "print(testing_dataset.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f298b99-0c26-4436-a6a3-bc227fd8b9fb",
   "metadata": {},
   "source": [
    "Turn Sequences into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb12c6c-f077-482c-a833-17d2485aac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ad44e-5074-4c21-8bbe-7a2968ccc9f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf9492f-f6d9-4dba-b63d-390ca68b5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "nonlinearity = 'tanh'\n",
    "output_size = 4\n",
    "# input_size, hidden_size, num_layers=1, nonlinearity='tanh', bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None\n",
    "model = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d4ce5-9a2e-4efd-972b-4a73124ee52d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "985381c6-2a9f-435e-a58c-57de3ce79901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# this optimizer will do gradient descent for us\n",
    "# experiment with learning rate and optimizer type\n",
    "learning_rate = 0.01;\n",
    "# note that we have to add all weights&biases, for both layers, to the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "# we add a learning rate scheduler, which will modify the learning rate during training\n",
    "# will initially start low, then increase it (\"warm up\"), and then gradually decrease it\n",
    "n_epochs = 100;\n",
    "batch_size = 120;\n",
    "num_updates = n_epochs*int(np.ceil(len(trainloader.dataset)/batch_size))\n",
    "print(num_updates)\n",
    "warmup_steps=10;\n",
    "def warmup_linear(x):\n",
    "    if x < warmup_steps:\n",
    "        lr=x/warmup_steps\n",
    "    else:\n",
    "        lr=max( (num_updates - x ) / (num_updates - warmup_steps), 0.)\n",
    "    return lr;\n",
    "#scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, warmup_linear);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a2ca5-3210-477e-bac0-419ded9b7644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "214a3363-ee43-4566-945f-a1df775924f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [4, 2]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m risk \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), labels\u001b[38;5;241m.\u001b[39msqueeze());\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# calculate gradients\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mrisk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m;\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# take the gradient step\u001b[39;00m\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep();\n",
      "File \u001b[1;32m~\\.conda\\envs\\rnn\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\rnn\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\rnn\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [4, 2]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "n_epochs = 25;\n",
    "hidden_state = torch.zeros((1, batch_size, hidden_size),device=device,requires_grad = True)\n",
    "\n",
    "#hidden_state.type(torch.float)\n",
    "for i in range(n_epochs):\n",
    "    for j, data in enumerate(trainloader):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        #For loop on sequence\n",
    "        #for t in range()\n",
    "\n",
    "        optimizer.zero_grad();\n",
    "        #forward phase - predictions by the model\n",
    "        #print(inputs.shape)\n",
    "        outputs, hidden_state = model(inputs, hidden_state);\n",
    "        #forward phase - risk/loss for the predictions\n",
    "        risk = criterion(outputs.squeeze(), labels.squeeze());\n",
    "\n",
    "        # calculate gradients\n",
    "        risk.backward(retain_graph=True);\n",
    "\n",
    "        # take the gradient step\n",
    "        optimizer.step();\n",
    "        #scheduler.step();\n",
    "\n",
    "        batch_risk=risk.item();\n",
    "    with (torch.no_grad()):\n",
    "      for j, data in enumerate(testloader):\n",
    "          inputs, labels = data\n",
    "          inputs=inputs.to(device);\n",
    "          labels=labels.to(device);\n",
    "          outputs, hidden_state = model(inputs);\n",
    "          risk = criterion(outputs.squeeze(), labels.squeeze());\n",
    "\n",
    "    print(i, risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85bf791b-ce26-4a2e-8dd7-853e10cf2af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 120])\n",
      "torch.Size([2, 120])\n",
      "torch.Size([4, 120])\n",
      "torch.Size([3, 6, 120])\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.ones([3,6,120])\n",
    "\n",
    "data_tensor = test_tensor[1,0:2]\n",
    "label_tensor = test_tensor[1,1:-1]\n",
    "    \n",
    "\n",
    "#print(label_tensor)\n",
    "\n",
    "#print(data_tensor)\n",
    "print(test_tensor[1].shape)\n",
    "print(data_tensor.shape)\n",
    "print(label_tensor.shape)\n",
    "\n",
    "print(test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02235775-e888-4393-ba47-6fc8f6549cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb305509-0a9d-486f-ba12-759382aa0d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b721bd4-4de1-4945-b702-2f3d4fb8f9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5115b2c-c142-462c-bc0e-2154c4e24fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
