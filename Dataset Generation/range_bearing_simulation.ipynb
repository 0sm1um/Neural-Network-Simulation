{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0baead1d-7b40-405b-bb4a-7efb950c6157",
   "metadata": {},
   "source": [
    "First we instantiate the simulator class we will use to generate our sequences. The Simulator handles all the particulars about the target being tracked. This simulation in particular is a Linear Time Invariant scenario of an object travelling at a constant velocity in two dimensions. However, it is being observed via a nonlinear measurement model.\n",
    "\n",
    "In particular it is a Bearing Range sensor positioned at the origin of the coordinate system. Measurements are collected as a 2 dimensional vector containing an angle, and a distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a91ec2-b74f-4154-8844-19d876af75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.groundtruth import GroundTruthPath, GroundTruthState\n",
    "from stonesoup.types.detection import Detection\n",
    "\n",
    "from stonesoup.types.track import Track\n",
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "\n",
    "class simulator():\n",
    "\n",
    "    def __init__(self, transition_model, measurement_model, state_range, meas_range = None, noise_range = None, meas_noise_range = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_model : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        measurement_model : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        \"\"\"\n",
    "        self.transition_model= transition_model\n",
    "        self.measurement_model = measurement_model\n",
    "        self.state_range = state_range\n",
    "        self.meas_range = meas_range\n",
    "        self.noise_range = noise_range\n",
    "        self.meas_noise_range = meas_noise_range\n",
    "\n",
    "    def _generate_ground_truth(self, prior, time_span):\n",
    "        \n",
    "        time_interval = time_span[1]-time_span[0]\n",
    "        ground_truth = GroundTruthPath([prior])\n",
    "        for k in range(1, len(time_span)):\n",
    "            ground_truth.append(GroundTruthState(\n",
    "                self.transition_model.function(ground_truth[k-1], noise=True, time_interval=time_interval),\n",
    "                timestamp=time_span[k-1]))\n",
    "        return ground_truth\n",
    "    \n",
    "    def _simulate_measurements(self, ground_truth):\n",
    "        #Simulate Measurements\n",
    "        measurements = []\n",
    "        for state in ground_truth:\n",
    "            measurement = self.measurement_model.function(state, noise=True)\n",
    "            measurements.append(Detection(measurement,\n",
    "                                          timestamp=state.timestamp,\n",
    "                                          measurement_model=self.measurement_model))\n",
    "        return measurements\n",
    "\n",
    "    def _initializer(self, time_stamp):\n",
    "        state_range_min = self.state_range[0]\n",
    "        state_range_max = self.state_range[1]\n",
    "        state_vector = StateVector(np.random.uniform(low=state_range_min, high=state_range_max))\n",
    "        while np.sqrt(state_vector[1]**2+state_vector[3]**2) < 0.15:\n",
    "            state_vector = StateVector(np.random.uniform(low=state_range_min, high=state_range_max))\n",
    "        meas_range_low = self.meas_range[0]\n",
    "        meas_range_max = self.meas_range[1]\n",
    "        self.measurement_model.translation_offset = np.random.uniform(low=meas_range_low, high=meas_range_max).reshape(len(meas_range_low),1)\n",
    "        #process_noise = \n",
    "        #self.transition_model. = np.randint(low=0,high=len(noise_range))\n",
    "        \n",
    "        return State(state_vector = state_vector, timestamp=time_stamp)\n",
    "\n",
    "    def generate_training_data(self, time_span):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ground_truth : :class:`~.GroundTruthPath`\n",
    "            StateMutableSequence type object used to store ground truth.\n",
    "        initial_state : :class:`~.State`\n",
    "            Initial state for the ground truth system. This MUST be a State,\n",
    "            not a State subclass, like GaussianState or EnsembleState.\n",
    "        prior : :class:`~.GaussianState` or :class:`~.EnsembleState`\n",
    "            Initial state prediction of tracking algorithm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        track : :class:`~.Track`\n",
    "            The Stone Soup track object which contains the list of updated \n",
    "            state predictions made by the tracking algorithm employed.\n",
    "        \"\"\"\n",
    "\n",
    "        #Simulate Measurements\n",
    "        initial_state = self._initializer(time_span[0])\n",
    "        ground_truth = self._generate_ground_truth(initial_state, time_span)\n",
    "        measurements = self._simulate_measurements(ground_truth)\n",
    "        \n",
    "        return ground_truth, measurements\n",
    "\n",
    "    def simulate_track(self, predictor, updater, initial_state, prior, time_span):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictor : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        updater : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        ground_truth : :class:`~.GroundTruthPath`\n",
    "            StateMutableSequence type object used to store ground truth.\n",
    "        initial_state : :class:`~.State`\n",
    "            Initial state for the ground truth system. This MUST be a State,\n",
    "            not a State subclass, like GaussianState or EnsembleState.\n",
    "        prior : :class:`~.GaussianState` or :class:`~.EnsembleState`\n",
    "            Initial state prediction of tracking algorithm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        track : :class:`~.Track`\n",
    "            The Stone Soup track object which contains the list of updated \n",
    "            state predictions made by the tracking algorithm employed.\n",
    "        \"\"\"\n",
    "\n",
    "        #Simulate Measurements\n",
    "        ground_truth = self._generate_ground_truth(initial_state, time_span)\n",
    "        measurements = self._simulate_measurements(ground_truth)\n",
    "        \n",
    "        #Initialize Loop Variables\n",
    "        track = Track()\n",
    "        for measurement in measurements:\n",
    "            prediction = predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "            hypothesis = SingleHypothesis(prediction, measurement)  # Group a prediction and measurement\n",
    "            posterior = updater.update(hypothesis)\n",
    "            track.append(posterior)\n",
    "            prior = track[-1]\n",
    "        return ground_truth, track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89b226e-0314-4d3b-ad70-5381641097e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from stonesoup.types.array import StateVector\n",
    "from stonesoup.types.state import State, GaussianState\n",
    "\n",
    "from stonesoup.models.transition.linear import (CombinedLinearGaussianTransitionModel,\n",
    "                                                ConstantVelocity)\n",
    "from stonesoup.models.measurement.nonlinear import CartesianToBearingRange\n",
    "\n",
    "\"\"\"\n",
    "    This script represents the code used to gather the data used in [PAPER HERE].\n",
    "    \n",
    "    This repository is structured such that different stone soup algorithms \n",
    "    can be run rapidly. Hopefully I've made it modular enough to \n",
    "    allow swapping of things like algorithms, and \"experiments\" by replacing\n",
    "    the desired transition and measurement models.\n",
    "    \n",
    "    The simulator class requires a transition and \n",
    "    measurement model, then the simulate_track method accepts a Stone Soup\n",
    "    Predictor, Updater, ground truth initial state, initial state for the\n",
    "    chosen algorithm, and a span of time which the simulation takes place over.\n",
    "    This time span should be an evenly spaced datetime.datetime list.\n",
    "    \n",
    "    The simulator then, is used to gather \"Track\" instances, and with a list \n",
    "    of tracks, RMSE can then be calculated.\n",
    "\"\"\"\n",
    "\n",
    "i = 60\n",
    "num_vectors = i*5\n",
    "\n",
    "\"\"\"\n",
    "    Here, we get our initial variables for simulation. For this, we are just\n",
    "    using a time span of 60 time instances spaced one second apart.\n",
    "\"\"\"\n",
    "\n",
    "timestamp = datetime.datetime(2021, 4, 2, 12, 28, 57)\n",
    "tMax = 60\n",
    "dt = 1\n",
    "tRange = tMax // dt\n",
    "plot_time_span = np.array([dt*i for i in range(tRange)])\n",
    "\n",
    "time_span = np.array([timestamp + datetime.timedelta(seconds=dt*i) for i in range(tRange)])\n",
    "\n",
    "\"\"\"\n",
    "Here we instantiate our transition and measurement models. These are the \n",
    "same models used in the StoneSoup Kalman Filter examples.\n",
    "\"\"\"\n",
    "\n",
    "q_x = 0.05\n",
    "q_y = 0.05\n",
    "sensor_x = 0  # Placing the sensor off-centre\n",
    "sensor_y = 0\n",
    "\n",
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(q_x),\n",
    "                                                          ConstantVelocity(q_y)])\n",
    "\n",
    "measurement_model = CartesianToBearingRange(\n",
    "ndim_state=4,\n",
    "mapping=(0, 2),\n",
    "noise_covar=np.diag([np.radians(1)**2, 0.1**2]),  # Covariance matrix. 0.2 degree variance in\n",
    "# bearing and 1 metre in range\n",
    "translation_offset=np.array([[sensor_x], [sensor_y]])  # Offset measurements to location of\n",
    "# sensor in cartesian.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3c7b9-e997-4aab-a103-a504880da933",
   "metadata": {},
   "source": [
    "In order to use this simulated data, we need to format it such that it can be loaded into PyTorch easily. Pytorch requires us to specify functions \"__get_item__\" and \"__len__\" in order to be usable by the generic Data Loader. I simply included the init and a helper function to append trajectories to the dataset for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b76935-2e6b-46e2-9712-e3bb6fb1815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Datasets should be specified on a per simulation basis\n",
    "\n",
    "#class sequence_generator(Dataset):\n",
    "\n",
    "class dataset_2D_bearing_range(Dataset):\n",
    "    #Range Bearing 2D Dataset Sequence Packer\n",
    "\n",
    "    def __init__(self, dataset, ground_truth=None, measurements=None):\n",
    "        if dataset == None:\n",
    "            gt = np.array([e.state_vector for e in ground_truth]).squeeze().T\n",
    "            gt = torch.tensor(gt.astype(dtype=np.float32),device = device)\n",
    "            ms = np.array([m.state_vector for m in measurements]).squeeze().T\n",
    "            ms = torch.tensor(ms.astype(dtype=np.float32),device = device)\n",
    "            self.dataset = torch.unsqueeze(torch.cat((ms,gt)),dim=0)\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "\n",
    "\n",
    "    def append_to_dataset(self, ground_truth, measurements):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ground_truth : :class:`~.list`\n",
    "            A list of Stonesoup States.\n",
    "        measurements : :class:`~.measurements`\n",
    "            The list of Stonesoup Measurements to be used.\n",
    "        \"\"\"\n",
    "\n",
    "        gt = np.array([e.state_vector for e in ground_truth]).squeeze().T\n",
    "        gt = torch.tensor(gt.astype(dtype=np.float32),device = device)\n",
    "        ms = np.array([m.state_vector for m in measurements]).squeeze().T\n",
    "        ms = torch.tensor(ms.astype(dtype=np.float32),device = device)\n",
    "        new_entry = torch.cat((ms,gt),dim=0)\n",
    "\n",
    "        self.dataset = torch.cat((self.dataset,torch.unsqueeze(new_entry,dim=0)),dim=0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx,0:2].T, self.dataset[idx,2:6].T\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5f341-04aa-4f3f-b554-c01f40df6165",
   "metadata": {},
   "source": [
    "This next module is something I call the Composer. The Composer's job is to return a useful dataset for use in PyTorch, and I will tell it how many trajectories I want, and it will call the relevant simulator and dataset methods to generate a dataset for the purpose of learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ce240c-0a77-4470-b1b1-5230d611b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Datasets should be specified on a per simulation basis\n",
    "# Should look up realistic values for radar precision and initial states\n",
    "# Come up with realistic constraints for initial velocities\n",
    "\n",
    "#class sequence_generator(Dataset):\n",
    "\n",
    "class dataset_composer():\n",
    "    #Range Bearing 2D Dataset Sequence Packer\n",
    "    def __init__(self, simulators, training_dataset, testing_dataset, batch_size, num_workers):\n",
    "        #pass a list of simulators\n",
    "        self.simulators = simulators\n",
    "        self.training_dataset = training_dataset\n",
    "        self.testing_dataset = testing_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def simulate_trajectories(self, training_dataset_len, testing_ratio):\n",
    "        for simulator in self.simulators:\n",
    "            trainset_length = int((training_dataset_len-1) / len(self.simulators)) # Partition dataset into sets from each simulator\n",
    "            for i in range(trainset_length):\n",
    "                ground_truth, measurements = simulator.generate_training_data(time_span)\n",
    "                self.training_dataset.append_to_dataset(ground_truth, measurements)\n",
    "            trainloader = DataLoader(self.training_dataset)\n",
    "\n",
    "            testset_length = int(((training_dataset_len)*testing_ratio -1)/len(self.simulators))\n",
    "            for i in range(testset_length):\n",
    "                ground_truth, measurements = simulator.generate_training_data(time_span)\n",
    "                self.testing_dataset.append_to_dataset(ground_truth, measurements)\n",
    "            testloader = DataLoader(self.testing_dataset)\n",
    "        return trainloader, testloader\n",
    "\n",
    "    def output_to_file(self, trainset_name, testset_name):\n",
    "        torch.save(self.training_dataset, trainset_name)\n",
    "        torch.save(self.testing_dataset, testset_name)\n",
    "\n",
    "    def read_from_file(self, training_file_name, testing_file_name, device):\n",
    "        trn = torch.load(training_file_name, map_location = device)\n",
    "        tst = torch.load(testing_file_name, map_location = device)\n",
    "        return DataLoader(dataset = trn, batch_size = self.batch_size, \n",
    "                          num_workers=self.num_workers, shuffle=True), DataLoader(dataset = tst, batch_size = self.batch_size,\n",
    "                                                                                  num_workers=self.num_workers, shuffle = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503acaa-e633-4dbf-b51f-2123301dd2c4",
   "metadata": {},
   "source": [
    "Here we instantiate the simulator, provide a range of permissable values for the initial conditions, noise coefficients, and specify the transition model, and measurement model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3514489-8f13-464a-8c87-296cb40cf9f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Position, Velocity, Position, Velocity\n",
    "state_range_min = np.array([-15, -2, -15, -2])\n",
    "state_range_max = np.array([15, 2, 15, 2])\n",
    "\n",
    "# Add some sort of miniumum speed\n",
    "\n",
    "meas_range_min = np.array([0, 0])\n",
    "meas_range_max = np.array([0, 0])\n",
    "\n",
    "# Randomization for process noise\n",
    "#process_noise_coefficients = [0.005, 0.05, 0.5]\n",
    "process_noise_coefficients = [0.05]\n",
    "\n",
    "nonlinear_simulator = simulator(transition_model=transition_model,\n",
    "                      measurement_model=measurement_model,\n",
    "                      state_range = (state_range_min, state_range_max),\n",
    "                      meas_range = (meas_range_min, meas_range_max)\n",
    ")\n",
    "\n",
    "ground_truth, measurements = nonlinear_simulator.generate_training_data(time_span)\n",
    "training_dataset =  dataset_2D_bearing_range(dataset = None, ground_truth = ground_truth, measurements = measurements)\n",
    "testing_dataset =  dataset_2D_bearing_range(dataset = None, ground_truth = ground_truth, measurements = measurements)\n",
    "\n",
    "#training_dataset_len = 1000000 #  1,000,000\n",
    "training_dataset_len = 100000 #  100,000\n",
    "#training_dataset_len = 10000\n",
    "testing_ratio = 0.15\n",
    "\n",
    "#batch_size = int(2**9) # 512, ?s per epoch\n",
    "#batch_size = int(2**8) # 256, 38s per epoch\n",
    "#batch_size = int(2**7) # 128, 38s per epoch\n",
    "#batch_size = int(2**6) # 64, 72s per epoch\n",
    "#batch_size = int(2**5) # 32, 138s per epoch\n",
    "batch_size = int(2**9)\n",
    "num_workers = 0\n",
    "\n",
    "dataset_composer = dataset_composer([nonlinear_simulator], testing_dataset, training_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "#trainloader, testloader = dataset_composer.simulate_trajectories(training_dataset_len, testing_ratio)\n",
    "#dataset_composer.output_to_file('training_data','testing_data')\n",
    "trainloader, testloader = dataset_composer.read_from_file('training_data', 'testing_data', device)\n",
    "#print('Training Dataset Length:', training_dataset.__len__())\n",
    "#print('Testing Dataset Length:',testing_dataset.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f298b99-0c26-4436-a6a3-bc227fd8b9fb",
   "metadata": {},
   "source": [
    "Turn Sequences into dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ad44e-5074-4c21-8bbe-7a2968ccc9f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf9492f-f6d9-4dba-b63d-390ca68b5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class UniDirectionalRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, nonlinearity, num_layers, device):\n",
    "        super(UniDirectionalRNN, self).__init__()\n",
    "        self.RNN = torch.nn.RNN(input_size, hidden_size, bidirectional=False, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, RNN_hidden):\n",
    "        RNN_output, RNN_hidden = self.RNN(input, RNN_hidden)\n",
    "        output = self.linear(RNN_output)\n",
    "        return output, RNN_hidden\n",
    "\n",
    "class BiDirectionalRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, nonlinearity, num_layers, device):\n",
    "        super(BiDirectionalRNN, self).__init__()\n",
    "        self.RNN = torch.nn.RNN(input_size, hidden_size, bidirectional=True, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(2*hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, RNN_hidden):\n",
    "        RNN_output, RNN_hidden = self.RNN(input, RNN_hidden)\n",
    "        output = self.linear(RNN_output)\n",
    "        return output, RNN_hidden\n",
    "\n",
    "class BiDirectionalLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, device):\n",
    "        super(BiDirectionalLSTM, self).__init__()\n",
    "        self.LSTM = torch.nn.LSTM(input_size, hidden_size, bidirectional=True, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(2*hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, LSTM_hidden, LSTM_cell):\n",
    "        LSTM_output, (LSTM_hidden, LSTM_cell) = self.LSTM(input, (LSTM_hidden, LSTM_cell))\n",
    "        output = self.linear(LSTM_output)\n",
    "        return output, (LSTM_hidden, LSTM_cell)\n",
    "\n",
    "class UniDirectionalLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, device):\n",
    "        super(UniDirectionalLSTM, self).__init__()\n",
    "        self.LSTM = torch.nn.LSTM(input_size, hidden_size, bidirectional=False, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, LSTM_hidden, LSTM_cell):\n",
    "        LSTM_output, (LSTM_hidden, LSTM_cell) = self.LSTM(input, (LSTM_hidden, LSTM_cell))\n",
    "        output = self.linear(LSTM_output)\n",
    "        return output, (LSTM_hidden, LSTM_cell)\n",
    "\n",
    "class EncoderDecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, device):\n",
    "        super(EncoderDecoderLSTM, self).__init__()\n",
    "        self.encoder = torch.nn.LSTM(input_size, hidden_size, bidirectional=True, num_layers=num_layers, device=device)\n",
    "        self.decoder = torch.nn.LSTM(hidden_size, hidden_size, bidirectional=True, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(2*hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, LSTM_hidden, LSTM_cell):\n",
    "        encoder_output, (encoder_hidden, encoder_cell) = self.encoder(input, (LSTM_hidden, LSTM_cell))\n",
    "        decoder_output, (decoder_hidden, decoder_cell) = self.decoder(input, (encoder_hidden, encoder_cell))\n",
    "        output = self.linear(LSTM_output)\n",
    "        return output, (encoder_hidden, encoder_cell), (decoder_hidden, decoder_cell)\n",
    "\n",
    "class MHATransformer(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=16, output_size = 4, nhead=4, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, device=None):\n",
    "        super(MHATransformer, self).__init__()\n",
    "        self.input_layer = torch.nn.Linear(input_size, hidden_size, device=device)\n",
    "        self.transformer = torch.nn.Transformer(d_model=hidden_size, nhead=nhead,\n",
    "                                                num_encoder_layers=num_encoder_layers,\n",
    "                                                num_decoder_layers=num_decoder_layers,\n",
    "                                                dim_feedforward=dim_feedforward,\n",
    "                                                batch_first=True,\n",
    "                                                device=device)\n",
    "        self.output_layer = torch.nn.Linear(hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden_input = self.input_layer(input)\n",
    "        transformer_output = self.transformer(hidden_input, hidden_input)\n",
    "        return self.output_layer(transformer_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2258a1b-5b6f-4971-8568-bae9e756e97c",
   "metadata": {},
   "source": [
    "Oogabooga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2f65b7-eaa7-419f-9ccf-a8cd8f9585fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001A089351F20>\n"
     ]
    }
   ],
   "source": [
    "input_size = 2\n",
    "output_size = 4\n",
    "\n",
    "UniRNN_hidden_size = 128\n",
    "UniRNN_num_layers = 3\n",
    "nonlinearity = 'relu'\n",
    "\n",
    "UniRNN = UniDirectionalRNN(input_size=input_size, hidden_size=UniRNN_hidden_size, \n",
    "                           output_size=output_size, nonlinearity=nonlinearity,\n",
    "                           num_layers=UniRNN_num_layers, device=device)\n",
    "\n",
    "BiRNN_hidden_size = 128\n",
    "BiRNN_num_layers = 3\n",
    "nonlinearity = 'relu'\n",
    "\n",
    "BiRNN = BiDirectionalRNN(input_size=input_size, hidden_size=BiRNN_hidden_size, \n",
    "                         output_size=output_size, nonlinearity=nonlinearity, \n",
    "                         num_layers=BiRNN_num_layers, device=device)\n",
    "\n",
    "UniLSTM_hidden_size = 128\n",
    "UniLSTM_num_layers = 3\n",
    "nonlinearity = 'relu'\n",
    "\n",
    "UniLSTM = UniDirectionalLSTM(input_size=input_size, hidden_size=UniLSTM_hidden_size, \n",
    "                             output_size=output_size, num_layers=UniLSTM_num_layers,\n",
    "                             device=device)\n",
    "\n",
    "BiLSTM_hidden_size = 128\n",
    "BiLSTM_num_layers = 3\n",
    "nonlinearity = 'relu'\n",
    "\n",
    "BiLSTM = BiDirectionalLSTM(input_size=input_size, hidden_size=BiLSTM_hidden_size, \n",
    "                           output_size=output_size, num_layers=BiLSTM_num_layers,\n",
    "                           device=device)\n",
    "\n",
    "print(BiLSTM.parameters())\n",
    "\n",
    "transformer_hidden_size = 32\n",
    "nhead = 16\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "\n",
    "Transformer = MHATransformer(input_size=input_size, hidden_size = transformer_hidden_size, \n",
    "                             output_size = output_size, nhead=nhead,\n",
    "                             num_encoder_layers=num_encoder_layers, \n",
    "                             num_decoder_layers=num_decoder_layers, \n",
    "                             dim_feedforward=dim_feedforward, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d4ce5-9a2e-4efd-972b-4a73124ee52d",
   "metadata": {},
   "source": [
    "Initialize Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "985381c6-2a9f-435e-a58c-57de3ce79901",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "#UniRNN_learning_rate = 0.000005;\n",
    "UniRNN_learning_rate = 0.00005;\n",
    "UniRNN_weight_decay = 0.000 #L2 Regularization Factor\n",
    "UniRNN_optimizer = torch.optim.Adam(UniRNN.parameters(),lr=UniRNN_learning_rate, weight_decay = UniRNN_weight_decay)\n",
    "#UniRNN_scheduler = torch.optim.lr_scheduler.LinearLR(UniRNN_optimizer, start_factor=1,end_factor = 0.01, total_iters=50)\n",
    "\n",
    "#BiRNN_learning_rate = 0.0000005;\n",
    "BiRNN_learning_rate = 0.00005;\n",
    "BiRNN_weight_decay = 0.000 #L2 Regularization Factor\n",
    "BiRNN_optimizer = torch.optim.Adam(BiRNN.parameters(),lr=BiRNN_learning_rate, weight_decay = BiRNN_learning_rate)\n",
    "#BiRNN_scheduler = torch.optim.lr_scheduler.LinearLR(BiRNN_optimizer, start_factor=1,end_factor = 0.01, total_iters=50)\n",
    "\n",
    "#UniLSTM_learning_rate = 0.000005;\n",
    "UniLSTM_learning_rate = 0.00005;\n",
    "UniLSTM_weight_decay = 0.000 #L2 Regularization Factor\n",
    "UniLSTM_optimizer = torch.optim.Adam(UniLSTM.parameters(),lr=UniLSTM_learning_rate, weight_decay = UniLSTM_weight_decay)\n",
    "#UniLSTM_scheduler = torch.optim.lr_scheduler.LinearLR(UniLSTM_optimizer, start_factor=1,end_factor = 0.01, total_iters=50)\n",
    "\n",
    "#BiLSTM_learning_rate = 0.0000005;\n",
    "BiLSTM_learning_rate = 0.00005;\n",
    "BiLSTM_weight_decay = 0.000 #L2 Regularization Factor\n",
    "BiLSTM_optimizer = torch.optim.Adam(BiLSTM.parameters(),lr=BiLSTM_learning_rate, weight_decay = BiLSTM_weight_decay)\n",
    "#BiLSTM_scheduler = torch.optim.lr_scheduler.LinearLR(BiLSTM_optimizer, start_factor=1,end_factor = 0.01, total_iters=50)\n",
    "\n",
    "#Transformer_Learning_rate = 0.0000005; # 0.0005 is is too fast, will not learn\n",
    "Transformer_Learning_rate = 0.00005; # 0.0005 is is too fast, will not learn\n",
    "TransformerWeight_decay = 0.000 #L2 Regularization Factor\n",
    "Transformer_optimizer = torch.optim.Adam(Transformer.parameters(),lr=Transformer_Learning_rate, weight_decay = TransformerWeight_decay)\n",
    "#Transformer_scheduler = torch.optim.lr_scheduler.LinearLR(Transformer_optimizer, start_factor=1, end_factor = 0.1, total_iters=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214fb703-df50-4988-b69c-9bfa2041e242",
   "metadata": {},
   "source": [
    "Lets run the EKF on the dataset to get a performance baseline. This is the class simulator to generate the tracks for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5fd891-f007-4f65-868a-b085e5d40ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class track_simulator():\n",
    "    def __init__(self, predictor, updater, dataloader, time_span):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_model : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        measurement_model : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        \"\"\"\n",
    "        self.predictor = predictor\n",
    "        self.updater = updater\n",
    "        self.dataloader = dataloader\n",
    "        self.time_span = time_span\n",
    "\n",
    "    def initializer(self, time_stamp, labels):\n",
    "        state_range_min = labels[0][0].cpu().numpy()\n",
    "        state_range_max = labels[0][1].cpu().numpy()\n",
    "        state_vector = StateVector(np.random.uniform(low=state_range_min, high=state_range_max))\n",
    "        return GaussianState(state_vector = state_vector, covar = np.eye(4), timestamp=time_stamp)\n",
    "\n",
    "    def _simulate_track(self, inputs, labels):\n",
    "        track = Track()\n",
    "        prior = self.initializer(self.time_span[0], labels)\n",
    "        for i in range(inputs.shape[1]):\n",
    "            measurement = Detection(state_vector=inputs[0,i].cpu().numpy(), timestamp = self.time_span[i])\n",
    "            prediction = self.predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "            posterior = self.updater.update(SingleHypothesis(prediction, measurement))\n",
    "            track.append(posterior)\n",
    "            prior = track[-1]\n",
    "        tk = np.array([e.state_vector for e in track]).squeeze().T\n",
    "        tk = torch.tensor(tk.astype(dtype=np.float32),device = device)\n",
    "        return tk.T\n",
    "\n",
    "    def generate_MSE(self):\n",
    "        avg_loss = nn.MSELoss()\n",
    "        trajectory_MSE = nn.MSELoss(reduction='none')\n",
    "        MSE = torch.zeros(1,tMax,4, device=device) # Make this auto detect it\n",
    "        test_loss = 0\n",
    "        for j, data in enumerate(self.dataloader):\n",
    "            inputs, labels = data\n",
    "            outputs = self._simulate_track(inputs, labels)\n",
    "            test_loss += avg_loss(outputs, labels.squeeze())\n",
    "            MSE += trajectory_MSE(outputs, labels.squeeze())\n",
    "        return test_loss / (j+1), MSE.squeeze()/len(self.dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ee269-9364-41f6-a5f0-624fa1b8ba71",
   "metadata": {},
   "source": [
    "Here we instantiate a testloader for use with the EKF (the EKF cannot handle batched inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b8ad95-9481-4840-b752-f02348a9c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = torch.load('testing_data', map_location = device)\n",
    "trajectory_testloader = DataLoader(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17f7a030-b0c2-4a77-b634-d8436ad13520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07285962253808975\n"
     ]
    }
   ],
   "source": [
    "from stonesoup.predictor.kalman import ExtendedKalmanPredictor\n",
    "#from stonesoup.updater.kalman import ExtendedKalmanUpdater\n",
    "\n",
    "#predictor = ExtendedKalmanPredictor(transition_model)\n",
    "#updater = ExtendedKalmanUpdater(measurement_model)\n",
    "\n",
    "#track_simulator = track_simulator(predictor, updater, trajectory_testloader, time_span)\n",
    "\n",
    "#EKF_epoch_loss, EKF_track = track_simulator.generate_MSE()\n",
    "\n",
    "#epoch_mse, EKF_MSE = track_simulator.generate_MSE()\n",
    "\n",
    "#print(epoch_mse)\n",
    "#plotter.two_by_two_MSE_vs_time([EKF_MSE], ['Extended Kalman Filter'])\n",
    "\n",
    "#torch.tensor(epoch_mse)\n",
    "#torch.save(epoch_mse,'EKF_epoch_mse')\n",
    "#torch.save(EKF_MSE,'EKF_MSE')\n",
    "\n",
    "stop_loss = torch.load('EKF_epoch_mse', map_location=device)\n",
    "stop_loss = stop_loss.item()\n",
    "EKF_MSE = torch.load('EKF_MSE', map_location=device)\n",
    "print(stop_loss)\n",
    "stop_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a35f4e3-74a5-4dfa-a706-e0503a9f3ab4",
   "metadata": {},
   "source": [
    "Calling the above training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "214a3363-ee43-4566-945f-a1df775924f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echo4\\.conda\\envs\\pt\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\echo4\\.conda\\envs\\pt\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 1 Completed in  73 s,   nan Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----   1056.814  :   922.002  -----\n",
      "-----   BiDirectional RNN:   -----    943.298  :   762.167  -----\n",
      "-----  UniDirectional LSTM:  -----   1112.332  :   979.215  -----\n",
      "-----  BiDirectional LSTM:   -----   1039.670  :   781.559  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 2 Completed in  73 s, 303.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    857.508  :   796.132  -----\n",
      "-----   BiDirectional RNN:   -----    637.136  :   486.946  -----\n",
      "-----  UniDirectional LSTM:  -----    877.374  :   790.794  -----\n",
      "-----  BiDirectional LSTM:   -----    617.387  :   502.019  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 3 Completed in  72 s, 301.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    747.062  :   702.916  -----\n",
      "-----   BiDirectional RNN:   -----    386.871  :   312.118  -----\n",
      "-----  UniDirectional LSTM:  -----    718.906  :   656.576  -----\n",
      "-----  BiDirectional LSTM:   -----    419.128  :   348.429  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 4 Completed in  72 s, 298.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    621.194  :   526.405  -----\n",
      "-----   BiDirectional RNN:   -----    256.447  :   208.457  -----\n",
      "-----  UniDirectional LSTM:  -----    599.012  :   547.973  -----\n",
      "-----  BiDirectional LSTM:   -----    290.514  :   240.839  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 5 Completed in  72 s, 297.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    464.766  :   415.302  -----\n",
      "-----   BiDirectional RNN:   -----    170.128  :   137.690  -----\n",
      "-----  UniDirectional LSTM:  -----    500.677  :   459.004  -----\n",
      "-----  BiDirectional LSTM:   -----    200.006  :   165.186  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 6 Completed in  72 s, 295.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    375.036  :   338.491  -----\n",
      "-----   BiDirectional RNN:   -----    111.746  :    90.352  -----\n",
      "-----  UniDirectional LSTM:  -----    418.637  :   382.957  -----\n",
      "-----  BiDirectional LSTM:   -----    135.254  :   109.937  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 7 Completed in  72 s, 294.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    304.610  :   274.874  -----\n",
      "-----   BiDirectional RNN:   -----     73.035  :    58.594  -----\n",
      "-----  UniDirectional LSTM:  -----    343.486  :   310.156  -----\n",
      "-----  BiDirectional LSTM:   -----     89.457  :    72.675  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 8 Completed in  72 s, 292.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    245.304  :   219.698  -----\n",
      "-----   BiDirectional RNN:   -----     47.239  :    37.648  -----\n",
      "-----  UniDirectional LSTM:  -----    281.016  :   256.012  -----\n",
      "-----  BiDirectional LSTM:   -----     59.186  :    48.025  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 9 Completed in  72 s, 291.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    198.296  :   179.691  -----\n",
      "-----   BiDirectional RNN:   -----     30.218  :    24.010  -----\n",
      "-----  UniDirectional LSTM:  -----    232.011  :   211.320  -----\n",
      "-----  BiDirectional LSTM:   -----     38.990  :    31.586  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 10 Completed in  72 s, 290.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    160.859  :   145.246  -----\n",
      "-----   BiDirectional RNN:   -----     19.228  :    15.262  -----\n",
      "-----  UniDirectional LSTM:  -----    191.027  :   173.889  -----\n",
      "-----  BiDirectional LSTM:   -----     25.496  :    20.567  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 11 Completed in  72 s, 288.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    130.310  :   117.306  -----\n",
      "-----   BiDirectional RNN:   -----     12.211  :     9.675  -----\n",
      "-----  UniDirectional LSTM:  -----    156.870  :   142.711  -----\n",
      "-----  BiDirectional LSTM:   -----     16.640  :    13.492  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 12 Completed in  73 s, 287.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----    104.105  :    93.242  -----\n",
      "-----   BiDirectional RNN:   -----      7.818  :     6.240  -----\n",
      "-----  UniDirectional LSTM:  -----    128.362  :   116.528  -----\n",
      "-----  BiDirectional LSTM:   -----     10.919  :     8.857  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 13 Completed in  73 s, 286.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----     83.330  :    74.915  -----\n",
      "-----   BiDirectional RNN:   -----      5.079  :     4.113  -----\n",
      "-----  UniDirectional LSTM:  -----    104.741  :    94.902  -----\n",
      "-----  BiDirectional LSTM:   -----      7.242  :     5.893  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 14 Completed in  72 s, 285.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----     66.786  :    59.878  -----\n",
      "-----   BiDirectional RNN:   -----      3.429  :     2.804  -----\n",
      "-----  UniDirectional LSTM:  -----     85.146  :    76.997  -----\n",
      "-----  BiDirectional LSTM:   -----      4.910  :     4.056  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 15 Completed in  72 s, 283.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----     52.975  :    47.225  -----\n",
      "-----   BiDirectional RNN:   -----      2.427  :     2.063  -----\n",
      "-----  UniDirectional LSTM:  -----     69.033  :    62.394  -----\n",
      "-----  BiDirectional LSTM:   -----      3.462  :     2.924  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 16 Completed in  72 s, 282.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----     41.857  :    37.323  -----\n",
      "-----   BiDirectional RNN:   -----      1.854  :     1.633  -----\n",
      "-----  UniDirectional LSTM:  -----     55.772  :    50.191  -----\n",
      "-----  BiDirectional LSTM:   -----      2.564  :     2.232  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 17 Completed in  72 s, 281.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----     33.036  :    29.383  -----\n",
      "-----   BiDirectional RNN:   -----      1.514  :     1.402  -----\n",
      "-----  UniDirectional LSTM:  -----     44.880  :    40.437  -----\n",
      "-----  BiDirectional LSTM:   -----      2.003  :     1.785  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 18 Completed in  72 s, 280.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----     25.979  :    23.049  -----\n",
      "-----   BiDirectional RNN:   -----      1.316  :     1.242  -----\n",
      "-----  UniDirectional LSTM:  -----     36.106  :    32.453  -----\n",
      "-----  BiDirectional LSTM:   -----      1.654  :     1.526  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 19 Completed in  73 s, 278.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----     20.354  :    17.982  -----\n",
      "-----   BiDirectional RNN:   -----      1.188  :     1.141  -----\n",
      "-----  UniDirectional LSTM:  -----     28.931  :    26.028  -----\n",
      "-----  BiDirectional LSTM:   -----      1.435  :     1.355  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 20 Completed in  72 s, 277.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----     15.868  :    14.021  -----\n",
      "-----   BiDirectional RNN:   -----      1.106  :     1.070  -----\n",
      "-----  UniDirectional LSTM:  -----     23.168  :    20.813  -----\n",
      "-----  BiDirectional LSTM:   -----      1.290  :     1.228  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 21 Completed in  72 s, 276.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----     12.394  :    10.944  -----\n",
      "-----   BiDirectional RNN:   -----      1.050  :     1.184  -----\n",
      "-----  UniDirectional LSTM:  -----     18.497  :    16.641  -----\n",
      "-----  BiDirectional LSTM:   -----      1.186  :     1.155  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 22 Completed in  72 s, 275.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      9.686  :     8.548  -----\n",
      "-----   BiDirectional RNN:   -----      1.014  :     1.003  -----\n",
      "-----  UniDirectional LSTM:  -----     14.779  :    13.269  -----\n",
      "-----  BiDirectional LSTM:   -----      1.116  :     1.103  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 23 Completed in  72 s, 274.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      7.584  :     6.697  -----\n",
      "-----   BiDirectional RNN:   -----      0.980  :     0.979  -----\n",
      "-----  UniDirectional LSTM:  -----     11.836  :    10.691  -----\n",
      "-----  BiDirectional LSTM:   -----      1.062  :     1.046  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 24 Completed in  72 s, 272.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      5.962  :     5.281  -----\n",
      "-----   BiDirectional RNN:   -----      0.957  :     0.946  -----\n",
      "-----  UniDirectional LSTM:  -----      9.489  :     8.533  -----\n",
      "-----  BiDirectional LSTM:   -----      1.024  :     1.025  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 25 Completed in  72 s, 271.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      4.717  :     4.173  -----\n",
      "-----   BiDirectional RNN:   -----      0.939  :     0.938  -----\n",
      "-----  UniDirectional LSTM:  -----      7.622  :     6.872  -----\n",
      "-----  BiDirectional LSTM:   -----      0.991  :     1.013  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 26 Completed in  73 s, 270.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      3.772  :     3.363  -----\n",
      "-----   BiDirectional RNN:   -----      0.925  :     0.957  -----\n",
      "-----  UniDirectional LSTM:  -----      6.188  :     5.542  -----\n",
      "-----  BiDirectional LSTM:   -----      0.968  :     0.970  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 27 Completed in  72 s, 269.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      3.057  :     2.737  -----\n",
      "-----   BiDirectional RNN:   -----      0.912  :     0.902  -----\n",
      "-----  UniDirectional LSTM:  -----      5.033  :     4.528  -----\n",
      "-----  BiDirectional LSTM:   -----      0.946  :     0.940  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 28 Completed in  72 s, 268.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      2.520  :     2.273  -----\n",
      "-----   BiDirectional RNN:   -----      0.902  :     0.916  -----\n",
      "-----  UniDirectional LSTM:  -----      4.137  :     3.758  -----\n",
      "-----  BiDirectional LSTM:   -----      0.930  :     0.942  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 29 Completed in  72 s, 266.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      2.120  :     1.945  -----\n",
      "-----   BiDirectional RNN:   -----      0.892  :     0.888  -----\n",
      "-----  UniDirectional LSTM:  -----      3.431  :     3.151  -----\n",
      "-----  BiDirectional LSTM:   -----      0.916  :     0.915  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 30 Completed in  72 s, 265.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      1.822  :     1.682  -----\n",
      "-----   BiDirectional RNN:   -----      0.885  :     0.902  -----\n",
      "-----  UniDirectional LSTM:  -----      2.900  :     2.686  -----\n",
      "-----  BiDirectional LSTM:   -----      0.905  :     0.926  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 31 Completed in  72 s, 264.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      1.603  :     1.495  -----\n",
      "-----   BiDirectional RNN:   -----      0.879  :     0.871  -----\n",
      "-----  UniDirectional LSTM:  -----      2.486  :     2.315  -----\n",
      "-----  BiDirectional LSTM:   -----      0.894  :     0.892  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 32 Completed in  72 s, 263.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      1.438  :     1.380  -----\n",
      "-----   BiDirectional RNN:   -----      0.873  :     0.869  -----\n",
      "-----  UniDirectional LSTM:  -----      2.157  :     2.010  -----\n",
      "-----  BiDirectional LSTM:   -----      0.885  :     0.880  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 33 Completed in  72 s, 261.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      1.315  :     1.257  -----\n",
      "-----   BiDirectional RNN:   -----      0.868  :     0.884  -----\n",
      "-----  UniDirectional LSTM:  -----      1.904  :     1.808  -----\n",
      "-----  BiDirectional LSTM:   -----      0.876  :     0.892  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 34 Completed in  72 s, 260.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      1.223  :     1.173  -----\n",
      "-----   BiDirectional RNN:   -----      0.863  :     0.870  -----\n",
      "-----  UniDirectional LSTM:  -----      1.713  :     1.639  -----\n",
      "-----  BiDirectional LSTM:   -----      0.871  :     0.874  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 35 Completed in  72 s, 259.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      1.153  :     1.115  -----\n",
      "-----   BiDirectional RNN:   -----      0.858  :     0.865  -----\n",
      "-----  UniDirectional LSTM:  -----      1.563  :     1.549  -----\n",
      "-----  BiDirectional LSTM:   -----      0.865  :     0.868  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 36 Completed in  72 s, 258.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      1.099  :     1.071  -----\n",
      "-----   BiDirectional RNN:   -----      0.856  :     0.854  -----\n",
      "-----  UniDirectional LSTM:  -----      1.441  :     1.400  -----\n",
      "-----  BiDirectional LSTM:   -----      0.858  :     0.862  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 37 Completed in  72 s, 257.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      1.058  :     1.041  -----\n",
      "-----   BiDirectional RNN:   -----      0.852  :     0.855  -----\n",
      "-----  UniDirectional LSTM:  -----      1.347  :     1.332  -----\n",
      "-----  BiDirectional LSTM:   -----      0.852  :     0.866  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 38 Completed in  72 s, 255.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      1.025  :     1.005  -----\n",
      "-----   BiDirectional RNN:   -----      0.848  :     0.851  -----\n",
      "-----  UniDirectional LSTM:  -----      1.272  :     1.241  -----\n",
      "-----  BiDirectional LSTM:   -----      0.849  :     0.856  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 39 Completed in  72 s, 254.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.999  :     0.990  -----\n",
      "-----   BiDirectional RNN:   -----      0.846  :     0.867  -----\n",
      "-----  UniDirectional LSTM:  -----      1.213  :     1.183  -----\n",
      "-----  BiDirectional LSTM:   -----      0.844  :     0.859  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 40 Completed in  72 s, 253.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.977  :     0.971  -----\n",
      "-----   BiDirectional RNN:   -----      0.843  :     0.876  -----\n",
      "-----  UniDirectional LSTM:  -----      1.163  :     1.152  -----\n",
      "-----  BiDirectional LSTM:   -----      0.840  :     0.841  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 41 Completed in  72 s, 252.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.959  :     0.960  -----\n",
      "-----   BiDirectional RNN:   -----      0.841  :     0.839  -----\n",
      "-----  UniDirectional LSTM:  -----      1.125  :     1.111  -----\n",
      "-----  BiDirectional LSTM:   -----      0.838  :     0.838  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 42 Completed in  72 s, 251.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.945  :     0.990  -----\n",
      "-----   BiDirectional RNN:   -----      0.838  :     0.852  -----\n",
      "-----  UniDirectional LSTM:  -----      1.092  :     1.079  -----\n",
      "-----  BiDirectional LSTM:   -----      0.835  :     0.856  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 43 Completed in  72 s, 249.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.932  :     0.932  -----\n",
      "-----   BiDirectional RNN:   -----      0.836  :     0.842  -----\n",
      "-----  UniDirectional LSTM:  -----      1.061  :     1.050  -----\n",
      "-----  BiDirectional LSTM:   -----      0.831  :     0.880  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 44 Completed in  72 s, 248.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.921  :     0.913  -----\n",
      "-----   BiDirectional RNN:   -----      0.835  :     0.853  -----\n",
      "-----  UniDirectional LSTM:  -----      1.036  :     1.037  -----\n",
      "-----  BiDirectional LSTM:   -----      0.829  :     0.835  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 45 Completed in  72 s, 247.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.912  :     0.911  -----\n",
      "-----   BiDirectional RNN:   -----      0.833  :     0.835  -----\n",
      "-----  UniDirectional LSTM:  -----      1.013  :     1.016  -----\n",
      "-----  BiDirectional LSTM:   -----      0.827  :     0.830  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 46 Completed in  72 s, 246.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.903  :     0.906  -----\n",
      "-----   BiDirectional RNN:   -----      0.832  :     0.854  -----\n",
      "-----  UniDirectional LSTM:  -----      0.994  :     0.999  -----\n",
      "-----  BiDirectional LSTM:   -----      0.826  :     0.845  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 47 Completed in  73 s, 245.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.896  :     0.894  -----\n",
      "-----   BiDirectional RNN:   -----      0.829  :     0.830  -----\n",
      "-----  UniDirectional LSTM:  -----      0.979  :     0.978  -----\n",
      "-----  BiDirectional LSTM:   -----      0.822  :     0.822  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 48 Completed in  72 s, 243.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.890  :     0.892  -----\n",
      "-----   BiDirectional RNN:   -----      0.827  :     0.860  -----\n",
      "-----  UniDirectional LSTM:  -----      0.964  :     0.972  -----\n",
      "-----  BiDirectional LSTM:   -----      0.820  :     0.886  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 49 Completed in  72 s, 242.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.884  :     0.884  -----\n",
      "-----   BiDirectional RNN:   -----      0.826  :     0.839  -----\n",
      "-----  UniDirectional LSTM:  -----      0.951  :     0.950  -----\n",
      "-----  BiDirectional LSTM:   -----      0.818  :     0.823  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 50 Completed in  72 s, 241.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.878  :     0.881  -----\n",
      "-----   BiDirectional RNN:   -----      0.824  :     0.827  -----\n",
      "-----  UniDirectional LSTM:  -----      0.937  :     0.942  -----\n",
      "-----  BiDirectional LSTM:   -----      0.816  :     0.826  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 51 Completed in  72 s, 240.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.874  :     0.871  -----\n",
      "-----   BiDirectional RNN:   -----      0.823  :     0.822  -----\n",
      "-----  UniDirectional LSTM:  -----      0.928  :     0.926  -----\n",
      "-----  BiDirectional LSTM:   -----      0.814  :     0.816  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 52 Completed in  73 s, 238.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.870  :     0.870  -----\n",
      "-----   BiDirectional RNN:   -----      0.822  :     0.822  -----\n",
      "-----  UniDirectional LSTM:  -----      0.920  :     0.922  -----\n",
      "-----  BiDirectional LSTM:   -----      0.813  :     0.816  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 53 Completed in  72 s, 237.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.865  :     0.865  -----\n",
      "-----   BiDirectional RNN:   -----      0.820  :     0.825  -----\n",
      "-----  UniDirectional LSTM:  -----      0.911  :     0.912  -----\n",
      "-----  BiDirectional LSTM:   -----      0.812  :     0.815  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 54 Completed in  73 s, 236.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.862  :     0.866  -----\n",
      "-----   BiDirectional RNN:   -----      0.821  :     0.824  -----\n",
      "-----  UniDirectional LSTM:  -----      0.906  :     0.922  -----\n",
      "-----  BiDirectional LSTM:   -----      0.811  :     0.814  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 55 Completed in  72 s, 235.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.859  :     0.870  -----\n",
      "-----   BiDirectional RNN:   -----      0.818  :     0.816  -----\n",
      "-----  UniDirectional LSTM:  -----      0.896  :     0.902  -----\n",
      "-----  BiDirectional LSTM:   -----      0.809  :     0.823  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 56 Completed in  72 s, 234.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.856  :     0.858  -----\n",
      "-----   BiDirectional RNN:   -----      0.818  :     0.816  -----\n",
      "-----  UniDirectional LSTM:  -----      0.891  :     0.896  -----\n",
      "-----  BiDirectional LSTM:   -----      0.808  :     0.807  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 57 Completed in  72 s, 232.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.853  :     0.861  -----\n",
      "-----   BiDirectional RNN:   -----      0.816  :     0.814  -----\n",
      "-----  UniDirectional LSTM:  -----      0.886  :     0.884  -----\n",
      "-----  BiDirectional LSTM:   -----      0.806  :     0.817  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 58 Completed in  72 s, 231.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.851  :     0.851  -----\n",
      "-----   BiDirectional RNN:   -----      0.816  :     0.822  -----\n",
      "-----  UniDirectional LSTM:  -----      0.882  :     0.883  -----\n",
      "-----  BiDirectional LSTM:   -----      0.806  :     0.816  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 59 Completed in  72 s, 230.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.848  :     0.856  -----\n",
      "-----   BiDirectional RNN:   -----      0.814  :     0.825  -----\n",
      "-----  UniDirectional LSTM:  -----      0.875  :     0.882  -----\n",
      "-----  BiDirectional LSTM:   -----      0.805  :     0.814  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 60 Completed in  72 s, 229.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.846  :     0.850  -----\n",
      "-----   BiDirectional RNN:   -----      0.814  :     0.822  -----\n",
      "-----  UniDirectional LSTM:  -----      0.871  :     0.876  -----\n",
      "-----  BiDirectional LSTM:   -----      0.804  :     0.802  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 61 Completed in  72 s, 227.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.844  :     0.852  -----\n",
      "-----   BiDirectional RNN:   -----      0.814  :     0.817  -----\n",
      "-----  UniDirectional LSTM:  -----      0.866  :     0.874  -----\n",
      "-----  BiDirectional LSTM:   -----      0.803  :     0.826  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 62 Completed in  72 s, 226.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.843  :     0.844  -----\n",
      "-----   BiDirectional RNN:   -----      0.811  :     0.824  -----\n",
      "-----  UniDirectional LSTM:  -----      0.864  :     0.867  -----\n",
      "-----  BiDirectional LSTM:   -----      0.802  :     0.803  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 63 Completed in  72 s, 225.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.840  :     0.850  -----\n",
      "-----   BiDirectional RNN:   -----      0.811  :     0.819  -----\n",
      "-----  UniDirectional LSTM:  -----      0.858  :     0.861  -----\n",
      "-----  BiDirectional LSTM:   -----      0.801  :     0.802  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 64 Completed in  72 s, 224.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.839  :     0.839  -----\n",
      "-----   BiDirectional RNN:   -----      0.810  :     0.817  -----\n",
      "-----  UniDirectional LSTM:  -----      0.856  :     0.855  -----\n",
      "-----  BiDirectional LSTM:   -----      0.800  :     0.801  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 65 Completed in  72 s, 223.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.837  :     0.837  -----\n",
      "-----   BiDirectional RNN:   -----      0.809  :     0.823  -----\n",
      "-----  UniDirectional LSTM:  -----      0.853  :     0.854  -----\n",
      "-----  BiDirectional LSTM:   -----      0.799  :     0.808  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 66 Completed in  72 s, 221.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.835  :     0.842  -----\n",
      "-----   BiDirectional RNN:   -----      0.808  :     0.860  -----\n",
      "-----  UniDirectional LSTM:  -----      0.850  :     0.861  -----\n",
      "-----  BiDirectional LSTM:   -----      0.798  :     0.827  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 67 Completed in  72 s, 220.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.834  :     0.840  -----\n",
      "-----   BiDirectional RNN:   -----      0.808  :     0.841  -----\n",
      "-----  UniDirectional LSTM:  -----      0.846  :     0.847  -----\n",
      "-----  BiDirectional LSTM:   -----      0.798  :     0.810  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 68 Completed in  72 s, 219.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.833  :     0.842  -----\n",
      "-----   BiDirectional RNN:   -----      0.807  :     0.821  -----\n",
      "-----  UniDirectional LSTM:  -----      0.844  :     0.853  -----\n",
      "-----  BiDirectional LSTM:   -----      0.798  :     0.801  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 69 Completed in  72 s, 218.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.832  :     0.836  -----\n",
      "-----   BiDirectional RNN:   -----      0.806  :     0.823  -----\n",
      "-----  UniDirectional LSTM:  -----      0.842  :     0.843  -----\n",
      "-----  BiDirectional LSTM:   -----      0.797  :     0.798  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 70 Completed in  72 s, 216.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.830  :     0.834  -----\n",
      "-----   BiDirectional RNN:   -----      0.806  :     0.807  -----\n",
      "-----  UniDirectional LSTM:  -----      0.839  :     0.845  -----\n",
      "-----  BiDirectional LSTM:   -----      0.796  :     0.803  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 71 Completed in  72 s, 215.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.829  :     0.830  -----\n",
      "-----   BiDirectional RNN:   -----      0.804  :     0.808  -----\n",
      "-----  UniDirectional LSTM:  -----      0.837  :     0.844  -----\n",
      "-----  BiDirectional LSTM:   -----      0.795  :     0.806  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 72 Completed in  72 s, 214.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.828  :     0.830  -----\n",
      "-----   BiDirectional RNN:   -----      0.804  :     0.845  -----\n",
      "-----  UniDirectional LSTM:  -----      0.835  :     0.842  -----\n",
      "-----  BiDirectional LSTM:   -----      0.795  :     0.797  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 73 Completed in  72 s, 213.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.826  :     0.833  -----\n",
      "-----   BiDirectional RNN:   -----      0.804  :     0.802  -----\n",
      "-----  UniDirectional LSTM:  -----      0.833  :     0.848  -----\n",
      "-----  BiDirectional LSTM:   -----      0.794  :     0.808  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 74 Completed in  72 s, 211.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.826  :     0.829  -----\n",
      "-----   BiDirectional RNN:   -----      0.801  :     0.811  -----\n",
      "-----  UniDirectional LSTM:  -----      0.831  :     0.831  -----\n",
      "-----  BiDirectional LSTM:   -----      0.793  :     0.816  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 75 Completed in  72 s, 210.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.825  :     0.827  -----\n",
      "-----   BiDirectional RNN:   -----      0.802  :     0.803  -----\n",
      "-----  UniDirectional LSTM:  -----      0.829  :     0.899  -----\n",
      "-----  BiDirectional LSTM:   -----      0.793  :     0.810  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 76 Completed in  72 s, 209.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.824  :     0.838  -----\n",
      "-----   BiDirectional RNN:   -----      0.801  :     0.826  -----\n",
      "-----  UniDirectional LSTM:  -----      0.828  :     0.832  -----\n",
      "-----  BiDirectional LSTM:   -----      0.792  :     0.836  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 77 Completed in  72 s, 208.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.823  :     0.827  -----\n",
      "-----   BiDirectional RNN:   -----      0.800  :     0.815  -----\n",
      "-----  UniDirectional LSTM:  -----      0.826  :     0.830  -----\n",
      "-----  BiDirectional LSTM:   -----      0.792  :     0.810  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 78 Completed in  72 s, 207.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.822  :     0.840  -----\n",
      "-----   BiDirectional RNN:   -----      0.799  :     0.835  -----\n",
      "-----  UniDirectional LSTM:  -----      0.825  :     0.837  -----\n",
      "-----  BiDirectional LSTM:   -----      0.790  :     0.814  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 79 Completed in  72 s, 205.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.821  :     0.822  -----\n",
      "-----   BiDirectional RNN:   -----      0.798  :     0.804  -----\n",
      "-----  UniDirectional LSTM:  -----      0.822  :     0.829  -----\n",
      "-----  BiDirectional LSTM:   -----      0.789  :     0.797  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 80 Completed in  72 s, 204.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.820  :     0.821  -----\n",
      "-----   BiDirectional RNN:   -----      0.797  :     0.794  -----\n",
      "-----  UniDirectional LSTM:  -----      0.821  :     0.826  -----\n",
      "-----  BiDirectional LSTM:   -----      0.788  :     0.789  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 81 Completed in  72 s, 203.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.819  :     0.822  -----\n",
      "-----   BiDirectional RNN:   -----      0.796  :     0.793  -----\n",
      "-----  UniDirectional LSTM:  -----      0.820  :     0.827  -----\n",
      "-----  BiDirectional LSTM:   -----      0.787  :     0.789  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 82 Completed in  72 s, 202.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.819  :     0.824  -----\n",
      "-----   BiDirectional RNN:   -----      0.796  :     0.808  -----\n",
      "-----  UniDirectional LSTM:  -----      0.818  :     0.830  -----\n",
      "-----  BiDirectional LSTM:   -----      0.786  :     0.792  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 83 Completed in  72 s, 200.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.818  :     0.827  -----\n",
      "-----   BiDirectional RNN:   -----      0.795  :     0.791  -----\n",
      "-----  UniDirectional LSTM:  -----      0.818  :     0.818  -----\n",
      "-----  BiDirectional LSTM:   -----      0.787  :     0.797  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 84 Completed in  72 s, 199.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.817  :     0.830  -----\n",
      "-----   BiDirectional RNN:   -----      0.794  :     0.838  -----\n",
      "-----  UniDirectional LSTM:  -----      0.817  :     0.823  -----\n",
      "-----  BiDirectional LSTM:   -----      0.786  :     0.820  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 85 Completed in  72 s, 198.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.816  :     0.829  -----\n",
      "-----   BiDirectional RNN:   -----      0.795  :     0.831  -----\n",
      "-----  UniDirectional LSTM:  -----      0.816  :     0.817  -----\n",
      "-----  BiDirectional LSTM:   -----      0.786  :     0.828  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 86 Completed in  72 s, 197.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.815  :     0.817  -----\n",
      "-----   BiDirectional RNN:   -----      0.794  :     0.799  -----\n",
      "-----  UniDirectional LSTM:  -----      0.815  :     0.820  -----\n",
      "-----  BiDirectional LSTM:   -----      0.785  :     0.788  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 87 Completed in  72 s, 196.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.815  :     0.839  -----\n",
      "-----   BiDirectional RNN:   -----      0.794  :     0.815  -----\n",
      "-----  UniDirectional LSTM:  -----      0.814  :     0.824  -----\n",
      "-----  BiDirectional LSTM:   -----      0.784  :     0.791  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 88 Completed in  72 s, 194.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.814  :     0.823  -----\n",
      "-----   BiDirectional RNN:   -----      0.793  :     0.813  -----\n",
      "-----  UniDirectional LSTM:  -----      0.812  :     0.818  -----\n",
      "-----  BiDirectional LSTM:   -----      0.784  :     0.788  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 89 Completed in  72 s, 193.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.813  :     0.817  -----\n",
      "-----   BiDirectional RNN:   -----      0.793  :     0.811  -----\n",
      "-----  UniDirectional LSTM:  -----      0.812  :     0.819  -----\n",
      "-----  BiDirectional LSTM:   -----      0.784  :     0.787  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 90 Completed in  72 s, 192.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.813  :     0.815  -----\n",
      "-----   BiDirectional RNN:   -----      0.792  :     0.798  -----\n",
      "-----  UniDirectional LSTM:  -----      0.811  :     0.821  -----\n",
      "-----  BiDirectional LSTM:   -----      0.783  :     0.788  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 91 Completed in  72 s, 191.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.812  :     0.855  -----\n",
      "-----   BiDirectional RNN:   -----      0.792  :     0.798  -----\n",
      "-----  UniDirectional LSTM:  -----      0.810  :     0.851  -----\n",
      "-----  BiDirectional LSTM:   -----      0.783  :     0.800  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 92 Completed in  72 s, 190.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.812  :     0.815  -----\n",
      "-----   BiDirectional RNN:   -----      0.791  :     0.790  -----\n",
      "-----  UniDirectional LSTM:  -----      0.808  :     0.825  -----\n",
      "-----  BiDirectional LSTM:   -----      0.783  :     0.784  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 93 Completed in  72 s, 188.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.811  :     0.815  -----\n",
      "-----   BiDirectional RNN:   -----      0.791  :     0.791  -----\n",
      "-----  UniDirectional LSTM:  -----      0.808  :     0.812  -----\n",
      "-----  BiDirectional LSTM:   -----      0.782  :     0.808  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 94 Completed in  72 s, 187.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.810  :     0.816  -----\n",
      "-----   BiDirectional RNN:   -----      0.791  :     0.806  -----\n",
      "-----  UniDirectional LSTM:  -----      0.806  :     0.812  -----\n",
      "-----  BiDirectional LSTM:   -----      0.781  :     0.793  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 95 Completed in  72 s, 186.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.810  :     0.824  -----\n",
      "-----   BiDirectional RNN:   -----      0.791  :     0.799  -----\n",
      "-----  UniDirectional LSTM:  -----      0.806  :     0.833  -----\n",
      "-----  BiDirectional LSTM:   -----      0.782  :     0.787  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 96 Completed in  72 s, 185.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.809  :     0.817  -----\n",
      "-----   BiDirectional RNN:   -----      0.790  :     0.793  -----\n",
      "-----  UniDirectional LSTM:  -----      0.805  :     0.813  -----\n",
      "-----  BiDirectional LSTM:   -----      0.781  :     0.798  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 97 Completed in  72 s, 183.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.809  :     0.818  -----\n",
      "-----   BiDirectional RNN:   -----      0.790  :     0.800  -----\n",
      "-----  UniDirectional LSTM:  -----      0.805  :     0.816  -----\n",
      "-----  BiDirectional LSTM:   -----      0.781  :     0.786  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 98 Completed in  72 s, 182.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.808  :     0.819  -----\n",
      "-----   BiDirectional RNN:   -----      0.790  :     0.789  -----\n",
      "-----  UniDirectional LSTM:  -----      0.804  :     0.807  -----\n",
      "-----  BiDirectional LSTM:   -----      0.781  :     0.783  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 99 Completed in  72 s, 181.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.807  :     0.825  -----\n",
      "-----   BiDirectional RNN:   -----      0.789  :     0.810  -----\n",
      "-----  UniDirectional LSTM:  -----      0.803  :     0.821  -----\n",
      "-----  BiDirectional LSTM:   -----      0.781  :     0.791  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 100 Completed in  72 s, 180.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.807  :     0.810  -----\n",
      "-----   BiDirectional RNN:   -----      0.789  :     0.790  -----\n",
      "-----  UniDirectional LSTM:  -----      0.802  :     0.812  -----\n",
      "-----  BiDirectional LSTM:   -----      0.780  :     0.782  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 101 Completed in  72 s, 179.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.806  :     0.807  -----\n",
      "-----   BiDirectional RNN:   -----      0.789  :     0.787  -----\n",
      "-----  UniDirectional LSTM:  -----      0.802  :     0.816  -----\n",
      "-----  BiDirectional LSTM:   -----      0.779  :     0.785  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 102 Completed in  72 s, 177.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.806  :     0.810  -----\n",
      "-----   BiDirectional RNN:   -----      0.788  :     0.788  -----\n",
      "-----  UniDirectional LSTM:  -----      0.802  :     0.804  -----\n",
      "-----  BiDirectional LSTM:   -----      0.779  :     0.787  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 103 Completed in  72 s, 176.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.805  :     0.833  -----\n",
      "-----   BiDirectional RNN:   -----      0.788  :     0.833  -----\n",
      "-----  UniDirectional LSTM:  -----      0.801  :     0.804  -----\n",
      "-----  BiDirectional LSTM:   -----      0.779  :     0.839  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 104 Completed in  72 s, 175.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.804  :     0.814  -----\n",
      "-----   BiDirectional RNN:   -----      0.789  :     0.801  -----\n",
      "-----  UniDirectional LSTM:  -----      0.800  :     0.804  -----\n",
      "-----  BiDirectional LSTM:   -----      0.779  :     0.778  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 105 Completed in  72 s, 174.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.804  :     0.806  -----\n",
      "-----   BiDirectional RNN:   -----      0.788  :     0.795  -----\n",
      "-----  UniDirectional LSTM:  -----      0.800  :     0.801  -----\n",
      "-----  BiDirectional LSTM:   -----      0.778  :     0.777  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 106 Completed in  72 s, 173.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.803  :     0.804  -----\n",
      "-----   BiDirectional RNN:   -----      0.788  :     0.789  -----\n",
      "-----  UniDirectional LSTM:  -----      0.799  :     0.801  -----\n",
      "-----  BiDirectional LSTM:   -----      0.779  :     0.786  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 107 Completed in  72 s, 171.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.802  :     0.824  -----\n",
      "-----   BiDirectional RNN:   -----      0.788  :     0.790  -----\n",
      "-----  UniDirectional LSTM:  -----      0.798  :     0.808  -----\n",
      "-----  BiDirectional LSTM:   -----      0.778  :     0.779  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 108 Completed in  72 s, 170.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.802  :     0.808  -----\n",
      "-----   BiDirectional RNN:   -----      0.787  :     0.805  -----\n",
      "-----  UniDirectional LSTM:  -----      0.798  :     0.807  -----\n",
      "-----  BiDirectional LSTM:   -----      0.778  :     0.814  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 109 Completed in  72 s, 169.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.801  :     0.805  -----\n",
      "-----   BiDirectional RNN:   -----      0.787  :     0.809  -----\n",
      "-----  UniDirectional LSTM:  -----      0.798  :     0.802  -----\n",
      "-----  BiDirectional LSTM:   -----      0.777  :     0.782  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 110 Completed in  72 s, 168.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.800  :     0.801  -----\n",
      "-----   BiDirectional RNN:   -----      0.791  :     0.790  -----\n",
      "-----  UniDirectional LSTM:  -----      0.797  :     0.805  -----\n",
      "-----  BiDirectional LSTM:   -----      0.778  :     0.787  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 111 Completed in  72 s, 167.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.800  :     0.817  -----\n",
      "-----   BiDirectional RNN:   -----      0.787  :     0.793  -----\n",
      "-----  UniDirectional LSTM:  -----      0.796  :     0.801  -----\n",
      "-----  BiDirectional LSTM:   -----      0.778  :     0.792  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 112 Completed in  72 s, 165.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.799  :     0.824  -----\n",
      "-----   BiDirectional RNN:   -----      0.787  :     0.801  -----\n",
      "-----  UniDirectional LSTM:  -----      0.796  :     0.803  -----\n",
      "-----  BiDirectional LSTM:   -----      0.777  :     0.777  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 113 Completed in  72 s, 164.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.798  :     0.814  -----\n",
      "-----   BiDirectional RNN:   -----      0.787  :     0.792  -----\n",
      "-----  UniDirectional LSTM:  -----      0.796  :     0.804  -----\n",
      "-----  BiDirectional LSTM:   -----      0.777  :     0.781  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 114 Completed in  72 s, 163.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.798  :     0.808  -----\n",
      "-----   BiDirectional RNN:   -----      0.787  :     0.787  -----\n",
      "-----  UniDirectional LSTM:  -----      0.796  :     0.830  -----\n",
      "-----  BiDirectional LSTM:   -----      0.777  :     0.783  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 115 Completed in  72 s, 162.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.797  :     0.800  -----\n",
      "-----   BiDirectional RNN:   -----      0.787  :     0.791  -----\n",
      "-----  UniDirectional LSTM:  -----      0.795  :     0.804  -----\n",
      "-----  BiDirectional LSTM:   -----      0.777  :     0.778  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 116 Completed in  72 s, 161.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.796  :     0.844  -----\n",
      "-----   BiDirectional RNN:   -----      0.790  :     0.828  -----\n",
      "-----  UniDirectional LSTM:  -----      0.795  :     0.807  -----\n",
      "-----  BiDirectional LSTM:   -----      0.777  :     0.831  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 117 Completed in  72 s, 159.8 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.796  :     0.804  -----\n",
      "-----   BiDirectional RNN:   -----      0.788  :     0.784  -----\n",
      "-----  UniDirectional LSTM:  -----      0.795  :     0.805  -----\n",
      "-----  BiDirectional LSTM:   -----      0.777  :     0.781  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 118 Completed in  72 s, 158.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.795  :     0.800  -----\n",
      "-----   BiDirectional RNN:   -----      0.786  :     0.793  -----\n",
      "-----  UniDirectional LSTM:  -----      0.793  :     0.798  -----\n",
      "-----  BiDirectional LSTM:   -----      0.776  :     0.782  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 119 Completed in  72 s, 157.4 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.795  :     0.797  -----\n",
      "-----   BiDirectional RNN:   -----      0.786  :     0.788  -----\n",
      "-----  UniDirectional LSTM:  -----      0.793  :     0.796  -----\n",
      "-----  BiDirectional LSTM:   -----      0.776  :     0.780  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 120 Completed in  72 s, 156.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.794  :     0.798  -----\n",
      "-----   BiDirectional RNN:   -----      0.785  :     0.787  -----\n",
      "-----  UniDirectional LSTM:  -----      0.793  :     0.804  -----\n",
      "-----  BiDirectional LSTM:   -----      0.776  :     0.787  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 121 Completed in  72 s, 154.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.794  :     0.800  -----\n",
      "-----   BiDirectional RNN:   -----      0.785  :     0.787  -----\n",
      "-----  UniDirectional LSTM:  -----      0.792  :     0.797  -----\n",
      "-----  BiDirectional LSTM:   -----      0.775  :     0.782  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 122 Completed in  72 s, 153.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.793  :     0.794  -----\n",
      "-----   BiDirectional RNN:   -----      0.785  :     0.792  -----\n",
      "-----  UniDirectional LSTM:  -----      0.792  :     0.796  -----\n",
      "-----  BiDirectional LSTM:   -----      0.775  :     0.773  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 123 Completed in  72 s, 152.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.793  :     0.803  -----\n",
      "-----   BiDirectional RNN:   -----      0.785  :     0.784  -----\n",
      "-----  UniDirectional LSTM:  -----      0.792  :     0.799  -----\n",
      "-----  BiDirectional LSTM:   -----      0.775  :     0.779  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 124 Completed in  72 s, 151.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.793  :     0.796  -----\n",
      "-----   BiDirectional RNN:   -----      0.787  :     0.800  -----\n",
      "-----  UniDirectional LSTM:  -----      0.791  :     0.797  -----\n",
      "-----  BiDirectional LSTM:   -----      0.775  :     0.788  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 125 Completed in  72 s, 150.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.792  :     0.823  -----\n",
      "-----   BiDirectional RNN:   -----      0.785  :     0.800  -----\n",
      "-----  UniDirectional LSTM:  -----      0.791  :     0.798  -----\n",
      "-----  BiDirectional LSTM:   -----      0.775  :     0.793  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 126 Completed in  72 s, 148.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.792  :     0.796  -----\n",
      "-----   BiDirectional RNN:   -----      0.785  :     0.852  -----\n",
      "-----  UniDirectional LSTM:  -----      0.791  :     0.801  -----\n",
      "-----  BiDirectional LSTM:   -----      0.775  :     0.795  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 127 Completed in  72 s, 147.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.791  :     0.793  -----\n",
      "-----   BiDirectional RNN:   -----      0.787  :     0.805  -----\n",
      "-----  UniDirectional LSTM:  -----      0.790  :     0.795  -----\n",
      "-----  BiDirectional LSTM:   -----      0.774  :     0.795  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 128 Completed in  72 s, 146.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.791  :     0.833  -----\n",
      "-----   BiDirectional RNN:   -----      0.783  :     0.837  -----\n",
      "-----  UniDirectional LSTM:  -----      0.791  :     0.813  -----\n",
      "-----  BiDirectional LSTM:   -----      0.774  :     0.812  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 129 Completed in  76 s, 145.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.791  :     0.796  -----\n",
      "-----   BiDirectional RNN:   -----      0.791  :     0.806  -----\n",
      "-----  UniDirectional LSTM:  -----      0.790  :     0.808  -----\n",
      "-----  BiDirectional LSTM:   -----      0.774  :     0.788  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 130 Completed in  81 s, 144.2 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.790  :     0.792  -----\n",
      "-----   BiDirectional RNN:   -----      0.784  :     0.795  -----\n",
      "-----  UniDirectional LSTM:  -----      0.790  :     0.801  -----\n",
      "-----  BiDirectional LSTM:   -----      0.774  :     0.776  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 131 Completed in  78 s, 143.1 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.790  :     0.799  -----\n",
      "-----   BiDirectional RNN:   -----      0.793  :     0.819  -----\n",
      "-----  UniDirectional LSTM:  -----      0.789  :     0.819  -----\n",
      "-----  BiDirectional LSTM:   -----      0.774  :     0.819  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 132 Completed in  78 s, 142.0 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.790  :     0.801  -----\n",
      "-----   BiDirectional RNN:   -----      0.789  :     0.794  -----\n",
      "-----  UniDirectional LSTM:  -----      0.789  :     0.794  -----\n",
      "-----  BiDirectional LSTM:   -----      0.774  :     0.786  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 133 Completed in  77 s, 140.9 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.789  :     0.794  -----\n",
      "-----   BiDirectional RNN:   -----      0.784  :     0.800  -----\n",
      "-----  UniDirectional LSTM:  -----      0.788  :     0.790  -----\n",
      "-----  BiDirectional LSTM:   -----      0.774  :     0.777  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 134 Completed in  78 s, 139.7 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.789  :     0.793  -----\n",
      "-----   BiDirectional RNN:   -----      0.791  :     0.809  -----\n",
      "-----  UniDirectional LSTM:  -----      0.788  :     0.795  -----\n",
      "-----  BiDirectional LSTM:   -----      0.773  :     0.788  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 135 Completed in  78 s, 138.6 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.789  :     0.797  -----\n",
      "-----   BiDirectional RNN:   -----      0.783  :     0.799  -----\n",
      "-----  UniDirectional LSTM:  -----      0.788  :     0.794  -----\n",
      "-----  BiDirectional LSTM:   -----      0.773  :     0.779  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 136 Completed in  78 s, 137.5 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.789  :     0.796  -----\n",
      "-----   BiDirectional RNN:   -----      0.784  :     0.791  -----\n",
      "-----  UniDirectional LSTM:  -----      0.787  :     0.792  -----\n",
      "-----  BiDirectional LSTM:   -----      0.773  :     0.778  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n",
      "----------------------------------------------------------------- \n",
      "-----  Epoch: 137 Completed in 109 s, 136.3 Minutes Remaining -----\n",
      "-----  Deep Neural Networks  -----  Train Loss : Test Loss  -----\n",
      "-----  UniDirectional RNN:   -----      0.788  :     0.788  -----\n",
      "-----   BiDirectional RNN:   -----      0.788  :     0.795  -----\n",
      "-----  UniDirectional LSTM:  -----      0.787  :     0.792  -----\n",
      "-----  BiDirectional LSTM:   -----      0.773  :     0.774  -----\n",
      "-----      Transformer:      -----      0.000  :     0.000  -----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stopping_list[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     UniRNN_outputs, UniRNN_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mUniRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUniRNN_hidden\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     UniRNN_test_loss \u001b[38;5;241m=\u001b[39m criterion(UniRNN_outputs, labels)\n\u001b[0;32m     93\u001b[0m     UniRNN_testing_loss_epoch[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m UniRNN_test_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36mUniDirectionalRNN.forward\u001b[1;34m(self, input, RNN_hidden)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, RNN_hidden):\n\u001b[1;32m---> 10\u001b[0m     RNN_output, RNN_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRNN_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(RNN_output)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, RNN_hidden\n",
      "File \u001b[1;32m~\\.conda\\envs\\pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pt\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:553\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 553\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_tanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    557\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_relu(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    558\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m    559\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 250\n",
    "\n",
    "stopping_list = [False, False, False, False, True]\n",
    "\n",
    "UniRNN_hidden = torch.rand((1*UniRNN_num_layers, tMax, UniRNN_hidden_size),device=device)\n",
    "\n",
    "BiRNN_hidden = torch.rand((2*BiRNN_num_layers, tMax, BiRNN_hidden_size),device=device)\n",
    "\n",
    "UniLSTM_hidden = torch.rand((1*UniLSTM_num_layers, tMax, UniLSTM_hidden_size),device=device)\n",
    "UniLSTM_cell = torch.zeros((1*UniLSTM_num_layers, tMax, UniLSTM_hidden_size),device=device)\n",
    "\n",
    "BiLSTM_hidden = torch.rand((2*BiLSTM_num_layers, tMax, BiLSTM_hidden_size),device=device)\n",
    "BiLSTM_cell = torch.zeros((2*BiLSTM_num_layers, tMax, BiLSTM_hidden_size),device=device)\n",
    "\n",
    "UniRNN_training_loss_epoch = np.zeros(n_epochs)\n",
    "BiRNN_training_loss_epoch = np.zeros(n_epochs)\n",
    "UniLSTM_training_loss_epoch = np.zeros(n_epochs)\n",
    "BiLSTM_training_loss_epoch = np.zeros(n_epochs)\n",
    "Transformer_training_loss_epoch = np.zeros(n_epochs)\n",
    "\n",
    "UniRNN_testing_loss_epoch = np.zeros(n_epochs)\n",
    "BiRNN_testing_loss_epoch = np.zeros(n_epochs)\n",
    "UniLSTM_testing_loss_epoch = np.zeros(n_epochs)\n",
    "BiLSTM_testing_loss_epoch = np.zeros(n_epochs)\n",
    "Transformer_testing_loss_epoch = np.zeros(n_epochs)\n",
    "\n",
    "training_time = np.zeros(n_epochs)\n",
    "\n",
    "i = 0\n",
    "while i < n_epochs and not all(stopping_list):\n",
    "    tic = time.perf_counter()\n",
    "    for j, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        UniRNN_optimizer.zero_grad()\n",
    "        BiRNN_optimizer.zero_grad()\n",
    "        UniLSTM_optimizer.zero_grad()\n",
    "        BiLSTM_optimizer.zero_grad()\n",
    "        Transformer_optimizer.zero_grad()\n",
    "\n",
    "        if stopping_list[0] == False:\n",
    "            UniRNN_outputs, UniRNN_hidden = UniRNN(inputs, UniRNN_hidden.detach())\n",
    "            UniRNN_train_loss = criterion(UniRNN_outputs, labels)\n",
    "            UniRNN_train_loss.backward()\n",
    "            UniRNN_optimizer.step()\n",
    "            UniRNN_training_loss_epoch[i] += UniRNN_train_loss.item()\n",
    "        if stopping_list[1] == False:\n",
    "            BiRNN_outputs, BiRNN_hidden = BiRNN(inputs, BiRNN_hidden.detach())\n",
    "            BiRNN_train_loss = criterion(BiRNN_outputs, labels)\n",
    "            BiRNN_train_loss.backward()\n",
    "            BiRNN_optimizer.step()\n",
    "            BiRNN_training_loss_epoch[i] += BiRNN_train_loss.item()\n",
    "        if stopping_list[2] == False:\n",
    "            UniLSTM_outputs, (UniLSTM_hidden, UniLSTM_cell) = UniLSTM(inputs, UniLSTM_hidden.detach(), UniLSTM_cell.detach())\n",
    "            UniLSTM_train_loss = criterion(UniLSTM_outputs, labels)\n",
    "            UniLSTM_train_loss.backward()\n",
    "            UniLSTM_optimizer.step()\n",
    "            UniLSTM_training_loss_epoch[i] += UniLSTM_train_loss.item()\n",
    "        if stopping_list[3] == False:\n",
    "            BiLSTM_outputs, (BiLSTM_hidden, BiLSTM_cell) = BiLSTM(inputs, BiLSTM_hidden.detach(), BiLSTM_cell.detach())\n",
    "            BiLSTM_train_loss = criterion(BiLSTM_outputs, labels)\n",
    "            BiLSTM_train_loss.backward()\n",
    "            BiLSTM_training_loss_epoch[i] += BiLSTM_train_loss.item()\n",
    "            BiLSTM_optimizer.step()\n",
    "        if stopping_list[4] == False:\n",
    "            Transformer_outputs = Transformer(inputs)\n",
    "            Transformer_train_loss = criterion(Transformer_outputs, labels)\n",
    "            Transformer_train_loss.backward()\n",
    "            Transformer_optimizer.step()\n",
    "            Transformer_training_loss_epoch[i] += Transformer_train_loss.item()\n",
    "\n",
    "        #UniRNN_scheduler.step()\n",
    "        #BiRNN_scheduler.step()\n",
    "        #UniLSTM_scheduler.step()\n",
    "        #BiLSTM_scheduler.step()\n",
    "        #Transformer_scheduler.step()\n",
    "\n",
    "    UniRNN_training_loss_epoch[i] = UniRNN_training_loss_epoch[i] / (j+1)\n",
    "    BiRNN_training_loss_epoch[i] = BiRNN_training_loss_epoch[i] / (j+1)\n",
    "    UniLSTM_training_loss_epoch[i] = UniLSTM_training_loss_epoch[i] / (j+1)\n",
    "    BiLSTM_training_loss_epoch[i] = BiLSTM_training_loss_epoch[i] / (j+1)\n",
    "    Transformer_training_loss_epoch[i] = Transformer_training_loss_epoch[i] / (j+1)\n",
    "\n",
    "    with (torch.no_grad()):\n",
    "        for j, data in enumerate(testloader):            \n",
    "            inputs, labels = data\n",
    "\n",
    "            if stopping_list[0] == False:\n",
    "                UniRNN_outputs, UniRNN_hidden = UniRNN(inputs, UniRNN_hidden.detach())\n",
    "                UniRNN_test_loss = criterion(UniRNN_outputs, labels)\n",
    "                UniRNN_testing_loss_epoch[i] += UniRNN_test_loss.item()\n",
    "            if stopping_list[1] == False:\n",
    "                BiRNN_outputs, BiRNN_hidden = BiRNN(inputs, BiRNN_hidden.detach())\n",
    "                BiRNN_test_loss = criterion(BiRNN_outputs, labels)\n",
    "                BiRNN_testing_loss_epoch[i] += BiRNN_test_loss.item()\n",
    "            if stopping_list[2] == False:\n",
    "                UniLSTM_outputs, (UniLSTM_hidden, UniLSTM_cell) = UniLSTM(inputs, UniLSTM_hidden.detach(), UniLSTM_cell.detach())\n",
    "                UniLSTM_test_loss = criterion(UniLSTM_outputs, labels)\n",
    "                UniLSTM_testing_loss_epoch[i] += UniLSTM_test_loss.item()\n",
    "            if stopping_list[3] == False:\n",
    "                BiLSTM_outputs, (BiLSTM_hidden, BiLSTM_cell) = BiLSTM(inputs, BiLSTM_hidden.detach(), BiLSTM_cell.detach())\n",
    "                BiLSTM_test_loss = criterion(BiLSTM_outputs, labels)\n",
    "                BiLSTM_testing_loss_epoch[i] += BiLSTM_test_loss.item()\n",
    "            if stopping_list[4] == False:\n",
    "                Transformer_outputs = Transformer(inputs)\n",
    "                Transformer_test_loss = criterion(Transformer_outputs, labels)\n",
    "                Transformer_testing_loss_epoch[i] += Transformer_test_loss.item()\n",
    "\n",
    "        UniRNN_testing_loss_epoch[i] = UniRNN_testing_loss_epoch[i]  / (j+1)\n",
    "        BiRNN_testing_loss_epoch[i] = BiRNN_testing_loss_epoch[i]  / (j+1)\n",
    "        UniLSTM_testing_loss_epoch[i] = UniLSTM_testing_loss_epoch[i] / (j+1)\n",
    "        BiLSTM_testing_loss_epoch[i] = BiLSTM_testing_loss_epoch[i] / (j+1)\n",
    "        Transformer_testing_loss_epoch[i] = Transformer_testing_loss_epoch[i] / (j+1)\n",
    "\n",
    "        if UniRNN_testing_loss_epoch[i] <= stop_loss:\n",
    "            stopping_list[0] = True\n",
    "        if BiRNN_testing_loss_epoch[i] <= stop_loss:\n",
    "            stopping_list[1] = True\n",
    "        if UniLSTM_testing_loss_epoch[i] <= stop_loss:\n",
    "            stopping_list[2] = True\n",
    "        if BiLSTM_testing_loss_epoch[i] <= stop_loss:\n",
    "            stopping_list[3] = True\n",
    "        if Transformer_testing_loss_epoch[i] <= stop_loss:\n",
    "            stopping_list[4] = True\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "    training_time[i] = toc-tic\n",
    "    print(\"-----------------------------------------------------------------\",\n",
    "          \"\\n-----  Epoch:\",i+1, \"Completed in\",\"{:3.0f}\".format(training_time[i]),\n",
    "          \"s,\",\"{:5.1f}\".format((n_epochs-(i+1))/60*np.mean(training_time[0:i])), \"Minutes Remaining -----\")\n",
    "    # num_epochs remaining = n_epochs - (i+1)\n",
    "    print(\"-----  Deep Neural Networks  -----\",\" Train Loss : Test Loss  -----\")\n",
    "    print(\"-----  UniDirectional RNN:   -----\",\n",
    "          \"{:10.3f}\".format(UniRNN_training_loss_epoch[i]) +'  :'+\"{:10.3f}\".format(UniRNN_testing_loss_epoch[i])+'  -----')\n",
    "    print(\"-----   BiDirectional RNN:   -----\",\n",
    "          \"{:10.3f}\".format(BiRNN_training_loss_epoch[i]) +'  :'+\"{:10.3f}\".format(BiRNN_testing_loss_epoch[i])+'  -----')\n",
    "    print(\"-----  UniDirectional LSTM:  -----\",\n",
    "          \"{:10.3f}\".format(UniLSTM_training_loss_epoch[i]) +'  :'+\"{:10.3f}\".format(UniLSTM_testing_loss_epoch[i])+'  -----')\n",
    "    print(\"-----  BiDirectional LSTM:   -----\",\n",
    "          \"{:10.3f}\".format(BiLSTM_training_loss_epoch[i]) +'  :'+\"{:10.3f}\".format(BiLSTM_testing_loss_epoch[i])+'  -----')\n",
    "    print(\"-----      Transformer:      -----\",\n",
    "          \"{:10.3f}\".format(Transformer_training_loss_epoch[i]) +'  :'+\"{:10.3f}\".format(Transformer_testing_loss_epoch[i])+'  -----')\n",
    "    i += 1\n",
    "\n",
    "UniRNN_training_loss_epoch=np.trim_zeros(UniRNN_training_loss_epoch)\n",
    "BiRNN_training_loss_epoch=np.trim_zeros(BiRNN_training_loss_epoch)\n",
    "UniLSTM_training_loss_epoch=np.trim_zeros(UniLSTM_training_loss_epoch)\n",
    "BiLSTM_training_loss_epoch=np.trim_zeros(BiLSTM_training_loss_epoch)\n",
    "Transformer_training_loss_epoch=np.trim_zeros(Transformer_training_loss_epoch)\n",
    "\n",
    "UniRNN_testing_loss_epoch =np.trim_zeros(UniRNN_testing_loss_epoch)\n",
    "BiRNN_testing_loss_epoch=np.trim_zeros(BiRNN_testing_loss_epoch)\n",
    "UniLSTM_testing_loss_epoch=np.trim_zeros(UniLSTM_testing_loss_epoch)\n",
    "BiLSTM_testing_loss_epoch=np.trim_zeros(BiLSTM_testing_loss_epoch)\n",
    "Transformer_testing_loss_epoch=np.trim_zeros(Transformer_testing_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efe313-64a7-47ce-9840-dfcacd5e5a75",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f50a9-f6cc-4f8a-b241-af7b992722e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class plotter():\n",
    "    def __init__(self):\n",
    "        a = 'Hello World'\n",
    "\n",
    "    def avg_loss_vs_epoch(self, training_loss_list, legend_list):\n",
    "        fig, Loss_combined_plot = plt.subplots()\n",
    "\n",
    "        height = 4\n",
    "        width = 6\n",
    "        \n",
    "        Loss_combined_plot.set_xlabel(\"Epoch\")\n",
    "        Loss_combined_plot.set_ylabel(\"Average Loss (RMSE)\")\n",
    "        Loss_combined_plot.set_title(\"Training and Testing Loss vs Time\")\n",
    "        Loss_combined_plot.figure.set_figwidth(width) # 6.4\n",
    "        Loss_combined_plot.figure.set_figheight(height) # 6.4\n",
    "        fig.tight_layout()\n",
    "\n",
    "        t = range(len(training_loss_list[0]))\n",
    "        i = 0\n",
    "        for Loss in training_loss_list:\n",
    "            Loss_combined_plot.plot(t, Loss, label = legend_list[i])\n",
    "            i += 1\n",
    "        Loss_combined_plot.legend(legend_list)\n",
    "        \n",
    "    def two_by_one_MSE_vs_time(self, MSE_list, legend_list):\n",
    "        fig, MSE_combined_plot = plt.subplots(1,2)\n",
    "    \n",
    "        scale_factor = 1.5\n",
    "        height = 6 * scale_factor\n",
    "        width = 9 * scale_factor\n",
    "        \n",
    "        MSE_combined_plot[0].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[0].set_ylabel(\"Root Mean Square Error (km)\")\n",
    "        MSE_combined_plot[0].set_title(\"Avg RMSE in Position vs Time\")\n",
    "        MSE_combined_plot[0].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[0].figure.set_figheight(height) # 6.4\n",
    "        MSE_combined_plot[1].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[1].set_ylabel(\"Root Mean Square Error (km/s)\")\n",
    "        MSE_combined_plot[1].set_title(\"Avg RMSE in Velocity vs Time\")\n",
    "        MSE_combined_plot[1].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[1].figure.set_figheight(height) # 6.4\n",
    "        fig.tight_layout()\n",
    "\n",
    "        t = range(len(time_span))\n",
    "        i = 0\n",
    "        for MSE in MSE_list:\n",
    "            MSE_x = MSE.T[0].cpu().numpy()\n",
    "            MSE_xv = MSE.T[1].cpu().numpy()\n",
    "            MSE_y = MSE.T[2].cpu().numpy()\n",
    "            MSE_yv = MSE.T[3].cpu().numpy()\n",
    "\n",
    "            MSE_pos = np.sqrt( (MSE_x + MSE_y) / 2 )\n",
    "            MSE_vel = np.sqrt( (MSE_xv + MSE_yv) / 2 )\n",
    "\n",
    "            MSE_combined_plot[0].plot(t, MSE_pos, label = legend_list[i])\n",
    "            MSE_combined_plot[1].plot(t, MSE_vel, label = legend_list[i])\n",
    "            i += 1\n",
    "        MSE_combined_plot[0].legend([legend_list])\n",
    "        MSE_combined_plot[1].legend([legend_list])\n",
    "\n",
    "    def two_by_two_MSE_vs_time(self, MSE_list, legend_list):\n",
    "        fig, MSE_combined_plot = plt.subplots(2,2)\n",
    "        scale_factor = 1.5\n",
    "        height = 6 * scale_factor\n",
    "        width = 9 * scale_factor\n",
    "        \n",
    "        MSE_combined_plot[0][0].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[0][0].set_ylabel(\"Root Mean Square Error (km)\")\n",
    "        MSE_combined_plot[0][0].set_title(\"Avg RMSE in Horizontal Position vs Time\")\n",
    "        MSE_combined_plot[0][0].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[0][0].figure.set_figheight(height) # 6.4\n",
    "        \n",
    "        MSE_combined_plot[1][0].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[1][0].set_ylabel(\"Root Mean Square Error (km)\")\n",
    "        MSE_combined_plot[1][0].set_title(\"Avg RMSE in Vertical Position vs Time\")\n",
    "        MSE_combined_plot[1][0].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[1][0].figure.set_figheight(height) # 6.4\n",
    "\n",
    "        MSE_combined_plot[0][1].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[0][1].set_ylabel(\"Root Mean Square Error (km/s)\")\n",
    "        MSE_combined_plot[0][1].set_title(\"Avg RMSE in Horizontal Velocity vs Time\")\n",
    "        MSE_combined_plot[0][1].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[0][1].figure.set_figheight(height) # 6.4\n",
    "        \n",
    "        MSE_combined_plot[1][1].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[1][1].set_ylabel(\"Root Mean Square Error (km/s)\")\n",
    "        MSE_combined_plot[1][1].set_title(\"Avg RMSE in Vertical Velocity vs Time\")\n",
    "        MSE_combined_plot[1][1].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[1][1].figure.set_figheight(height) # 6.4\n",
    "        fig.tight_layout()\n",
    "\n",
    "        t = range(len(time_span))\n",
    "        i = 0\n",
    "        for MSE in MSE_list:\n",
    "            MSE_x = MSE.T[0].cpu().numpy()\n",
    "            MSE_xv = MSE.T[1].cpu().numpy()\n",
    "            MSE_y = MSE.T[2].cpu().numpy()\n",
    "            MSE_yv = MSE.T[3].cpu().numpy()\n",
    "\n",
    "            MSE_combined_plot[0][0].plot(t, MSE_x, label = legend_list[i])\n",
    "            #MSE_combined_plot[0][0].legend([legend_list[i]])\n",
    "            \n",
    "            MSE_combined_plot[1][0].plot(t, MSE_y, label = legend_list[i])\n",
    "            #MSE_combined_plot[1][0].legend([legend_list[i]])\n",
    "            \n",
    "            MSE_combined_plot[0][1].plot(t, MSE_xv, label = legend_list[i])\n",
    "            #MSE_combined_plot[0][1].legend([legend_list[i]])\n",
    "            \n",
    "            MSE_combined_plot[1][1].plot(t, MSE_yv, label = legend_list[i])\n",
    "            #MSE_combined_plot[1][1].legend([legend_list[i]])\n",
    "            i += 1\n",
    "\n",
    "        MSE_combined_plot[0][0].legend(legend_list)\n",
    "        MSE_combined_plot[1][0].legend(legend_list)\n",
    "        MSE_combined_plot[0][1].legend(legend_list)\n",
    "        MSE_combined_plot[1][1].legend(legend_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0bd32-f211-4b9a-b2e0-27e9a57b484e",
   "metadata": {},
   "source": [
    "Training Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b3993-ce58-454c-89cb-1c0ce3007fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = plotter()\n",
    "\n",
    "#plotter.two_by_two_MSE_vs_time([EKF_MSE], ['Extended Kalman Filter'])\n",
    "\n",
    "legend_list = ['Unidirectional RNN Training Loss', 'Unidirectional RNN Testing Loss']\n",
    "plotter.avg_loss_vs_epoch([UniRNN_training_loss_epoch, UniRNN_testing_loss_epoch], legend_list)\n",
    "\n",
    "legend_list = ['Bidirectional RNN Training Loss', 'Bidirectional RNN Testing Loss']\n",
    "plotter.avg_loss_vs_epoch([BiRNN_training_loss_epoch, BiRNN_testing_loss_epoch], legend_list)\n",
    "\n",
    "legend_list = ['Unidirectional LSTM Training Loss', 'Unidirectional LSTM Testing Loss']\n",
    "plotter.avg_loss_vs_epoch([UniLSTM_training_loss_epoch, UniLSTM_testing_loss_epoch], legend_list)\n",
    "\n",
    "legend_list = ['Bidirectional LSTM Training Loss', 'Bidirectional LSTM Testing Loss']\n",
    "plotter.avg_loss_vs_epoch([BiLSTM_training_loss_epoch, BiLSTM_testing_loss_epoch], legend_list)\n",
    "\n",
    "legend_list = ['Transformer Training Loss', 'Transformer Testing Loss']\n",
    "plotter.avg_loss_vs_epoch([Transformer_training_loss_epoch, Transformer_testing_loss_epoch], legend_list)\n",
    "'''\n",
    "legend_list = ['Unidirectional RNN Testing Loss', 'Bidirectional RNN Testing Loss',\n",
    "               'Unidirectional LSTM Testing Loss', 'Bidirectional LSTM Testing Loss']\n",
    "plotter.avg_loss_vs_epoch([UniRNN_training_loss_epoch, \n",
    "                           BiRNN_testing_loss_epoch,\n",
    "                           UniLSTM_training_loss_epoch,\n",
    "                           BiLSTM_training_loss_epoch, legend_list)\n",
    "'''\n",
    "legend_list = ['Unidirectional RNN Testing Loss', 'Bidirectional RNN Testing Loss',\n",
    "               'Unidirectional LSTM Testing Loss', 'Bidirectional LSTM Testing Loss',\n",
    "               'Transformer Testing Loss']\n",
    "plotter.avg_loss_vs_epoch([UniRNN_training_loss_epoch, \n",
    "                           BiRNN_testing_loss_epoch,\n",
    "                           UniLSTM_training_loss_epoch,\n",
    "                           BiLSTM_training_loss_epoch,\n",
    "                           Transformer_training_loss_epoch], legend_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a2a3e-77c0-4611-91a7-c029fe85da1a",
   "metadata": {},
   "source": [
    "Trajectory MSE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4c174-f4cb-4486-936e-7ec66440f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_mse_func = nn.MSELoss(reduction='none')\n",
    "tst = torch.load('testing_data', map_location = device)\n",
    "trajectory_testloader = DataLoader(tst)\n",
    "\n",
    "UniRNN_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "BiRNN_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "UniLSTM_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "BiLSTM_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "Transformer_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "\n",
    "with (torch.no_grad()):\n",
    "    for j, data in enumerate(trajectory_testloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        UniRNN_outputs, UniRNN_hidden = UniRNN(inputs, UniRNN_hidden.detach())\n",
    "        BiRNN_outputs, BiRNN_hidden = BiRNN(inputs, BiRNN_hidden.detach())\n",
    "        UniLSTM_outputs, (UniLSTM_hidden, UniLSTM_cell) = UniLSTM(inputs, UniLSTM_hidden.detach(), UniLSTM_cell.detach())\n",
    "        BiLSTM_outputs, (BiLSTM_hidden, BiLSTM_cell) = BiLSTM(inputs, BiLSTM_hidden.detach(), BiLSTM_cell.detach())\n",
    "        Transformer_outputs = Transformer(inputs)\n",
    "\n",
    "        UniRNN_test_loss = criterion(UniRNN_outputs, labels)\n",
    "        BiRNN_test_loss = criterion(BiRNN_outputs, labels)\n",
    "        UniLSTM_test_loss = criterion(UniLSTM_outputs, labels)\n",
    "        BiLSTM_test_loss = criterion(BiLSTM_outputs, labels)\n",
    "        Transformer_test_loss = criterion(Transformer_outputs, labels)\n",
    "\n",
    "        UniRNN_trajectory_MSE += trajectory_mse_func(UniRNN_outputs.squeeze(), labels.squeeze())\n",
    "        BiRNN_trajectory_MSE += trajectory_mse_func(BiRNN_outputs.squeeze(), labels.squeeze())\n",
    "        UniLSTM_trajectory_MSE += trajectory_mse_func(UniLSTM_outputs.squeeze(), labels.squeeze())\n",
    "        BiLSTM_trajectory_MSE += trajectory_mse_func(BiLSTM_outputs.squeeze(), labels.squeeze())\n",
    "        Transformer_trajectory_MSE += trajectory_mse_func(Transformer_outputs.squeeze(), labels.squeeze())\n",
    "\n",
    "    UniRNN_testing_MSE = UniRNN_trajectory_MSE / (j+1)\n",
    "    BiRNN_testing_MSE = BiRNN_trajectory_MSE / (j+1)\n",
    "    UniLSTM_testing_MSE = UniLSTM_trajectory_MSE / (j+1)\n",
    "    BiLSTM_testing_MSE = BiLSTM_trajectory_MSE / (j+1)\n",
    "    Transformer_testing_MSE = Transformer_trajectory_MSE / (j+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d1e72-91bb-409c-98e7-dab000104b18",
   "metadata": {},
   "source": [
    "This Plotter class contains all of the info to generate the plots used in the paper. Each method accepts it's own standardized input and handles any data preprocessing internally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07b1ec-59f8-478d-a761-8ac2611a27d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "750bb129-d91e-41fd-b8b8-fa9552f34f54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f94768-f665-41b0-b070-ef71c7b88985",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = [UniRNN_testing_MSE, BiRNN_testing_MSE, UniLSTM_testing_MSE, BiLSTM_testing_MSE, Transformer_testing_MSE]\n",
    "legend_list = ['Unidirectional RNN', 'Bidirectional RNN', 'Unidirectional LSTM', 'Bidirectional LSTM', 'Transformer']\n",
    "plotter.two_by_one_MSE_vs_time(mse_list, legend_list)\n",
    "plotter.two_by_two_MSE_vs_time(mse_list, legend_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2359d6-d880-48ab-baf9-2138c7074505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1edba1-ff3d-47e5-8e56-4244b785c21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54a1f9-b8a1-4321-bee5-8163941625fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e07030b-182d-4ce6-927c-29f561e26498",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cc125-658a-43f5-942a-9ecf541188ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
