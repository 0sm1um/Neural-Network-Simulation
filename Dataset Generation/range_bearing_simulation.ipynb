{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0baead1d-7b40-405b-bb4a-7efb950c6157",
   "metadata": {},
   "source": [
    "First we instantiate the simulator class we will use to generate our sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a91ec2-b74f-4154-8844-19d876af75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.groundtruth import GroundTruthPath, GroundTruthState\n",
    "from stonesoup.types.detection import Detection\n",
    "\n",
    "from stonesoup.types.track import Track\n",
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "\n",
    "class simulator():\n",
    "\n",
    "    def __init__(self, transition_model, measurement_model, state_range, meas_range = None, noise_range = None, meas_noise_range = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_model : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        measurement_model : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        \"\"\"\n",
    "        self.transition_model= transition_model\n",
    "        self.measurement_model = measurement_model\n",
    "        self.state_range = state_range\n",
    "        self.meas_range = meas_range\n",
    "        self.noise_range = noise_range\n",
    "        self.meas_noise_range = meas_noise_range\n",
    "\n",
    "    def _generate_ground_truth(self, prior, time_span):\n",
    "        \n",
    "        time_interval = time_span[1]-time_span[0]\n",
    "        ground_truth = GroundTruthPath([prior])\n",
    "        for k in range(1, len(time_span)):\n",
    "            ground_truth.append(GroundTruthState(\n",
    "                self.transition_model.function(ground_truth[k-1], noise=True, time_interval=time_interval),\n",
    "                timestamp=time_span[k-1]))\n",
    "        return ground_truth\n",
    "    \n",
    "    def _simulate_measurements(self, ground_truth):\n",
    "        #Simulate Measurements\n",
    "        measurements = []\n",
    "        for state in ground_truth:\n",
    "            measurement = self.measurement_model.function(state, noise=True)\n",
    "            measurements.append(Detection(measurement,\n",
    "                                          timestamp=state.timestamp,\n",
    "                                          measurement_model=self.measurement_model))\n",
    "        return measurements\n",
    "\n",
    "    def _initializer(self, time_stamp):\n",
    "        state_range_min = self.state_range[0]\n",
    "        state_range_max = self.state_range[1]\n",
    "        state_vector = StateVector(np.random.uniform(low=state_range_min, high=state_range_max))\n",
    "        while np.sqrt(state_vector[1]**2+state_vector[3]**2) < 0.25:\n",
    "            state_vector = StateVector(np.random.uniform(low=state_range_min, high=state_range_max))\n",
    "        meas_range_low = self.meas_range[0]\n",
    "        meas_range_max = self.meas_range[1]\n",
    "        self.measurement_model.translation_offset = np.random.uniform(low=meas_range_low, high=meas_range_max).reshape(len(meas_range_low),1)\n",
    "        #process_noise = \n",
    "        #self.transition_model. = np.randint(low=0,high=len(noise_range))\n",
    "        \n",
    "        return State(state_vector = state_vector, timestamp=time_stamp)\n",
    "\n",
    "    def generate_training_data(self, time_span):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ground_truth : :class:`~.GroundTruthPath`\n",
    "            StateMutableSequence type object used to store ground truth.\n",
    "        initial_state : :class:`~.State`\n",
    "            Initial state for the ground truth system. This MUST be a State,\n",
    "            not a State subclass, like GaussianState or EnsembleState.\n",
    "        prior : :class:`~.GaussianState` or :class:`~.EnsembleState`\n",
    "            Initial state prediction of tracking algorithm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        track : :class:`~.Track`\n",
    "            The Stone Soup track object which contains the list of updated \n",
    "            state predictions made by the tracking algorithm employed.\n",
    "        \"\"\"\n",
    "\n",
    "        #Simulate Measurements\n",
    "        initial_state = self._initializer(time_span[0])\n",
    "        ground_truth = self._generate_ground_truth(initial_state, time_span)\n",
    "        measurements = self._simulate_measurements(ground_truth)\n",
    "        \n",
    "        return ground_truth, measurements\n",
    "\n",
    "    def simulate_track(self, predictor, updater, initial_state, prior, time_span):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictor : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        updater : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        ground_truth : :class:`~.GroundTruthPath`\n",
    "            StateMutableSequence type object used to store ground truth.\n",
    "        initial_state : :class:`~.State`\n",
    "            Initial state for the ground truth system. This MUST be a State,\n",
    "            not a State subclass, like GaussianState or EnsembleState.\n",
    "        prior : :class:`~.GaussianState` or :class:`~.EnsembleState`\n",
    "            Initial state prediction of tracking algorithm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        track : :class:`~.Track`\n",
    "            The Stone Soup track object which contains the list of updated \n",
    "            state predictions made by the tracking algorithm employed.\n",
    "        \"\"\"\n",
    "\n",
    "        #Simulate Measurements\n",
    "        ground_truth = self._generate_ground_truth(initial_state, time_span)\n",
    "        measurements = self._simulate_measurements(ground_truth)\n",
    "        \n",
    "        #Initialize Loop Variables\n",
    "        track = Track()\n",
    "        for measurement in measurements:\n",
    "            prediction = predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "            hypothesis = SingleHypothesis(prediction, measurement)  # Group a prediction and measurement\n",
    "            posterior = updater.update(hypothesis)\n",
    "            track.append(posterior)\n",
    "            prior = track[-1]\n",
    "        return ground_truth, track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc4d79-f839-49f3-87f6-7ef115d95ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89b226e-0314-4d3b-ad70-5381641097e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "from stonesoup.types.array import StateVector, CovarianceMatrix\n",
    "from stonesoup.types.state import State, GaussianState\n",
    "\n",
    "from stonesoup.models.transition.linear import (CombinedLinearGaussianTransitionModel,\n",
    "                                                ConstantVelocity)\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "from stonesoup.updater.kalman import KalmanUpdater, ExtendedKalmanUpdater\n",
    "from stonesoup.predictor.ensemble import EnsemblePredictor\n",
    "from stonesoup.predictor.kalman import KalmanPredictor, ExtendedKalmanPredictor\n",
    "from stonesoup.models.measurement.nonlinear import CartesianToBearingRange\n",
    "\n",
    "\"\"\"\n",
    "    This script represents the code used to gather the data used in [PAPER HERE].\n",
    "    \n",
    "    This repository is structured such that different stone soup algorithms \n",
    "    can be run rapidly. Hopefully I've made it modular enough to \n",
    "    allow swapping of things like algorithms, and \"experiments\" by replacing\n",
    "    the desired transition and measurement models.\n",
    "    \n",
    "    The simulator class requires a transition and \n",
    "    measurement model, then the simulate_track method accepts a Stone Soup\n",
    "    Predictor, Updater, ground truth initial state, initial state for the\n",
    "    chosen algorithm, and a span of time which the simulation takes place over.\n",
    "    This time span should be an evenly spaced datetime.datetime list.\n",
    "    \n",
    "    The simulator then, is used to gather \"Track\" instances, and with a list \n",
    "    of tracks, RMSE can then be calculated.\n",
    "\"\"\"\n",
    "\n",
    "i = 60\n",
    "num_vectors = i*5\n",
    "\n",
    "\"\"\"\n",
    "    Here, we get our initial variables for simulation. For this, we are just\n",
    "    using a time span of 60 time instances spaced one second apart.\n",
    "\"\"\"\n",
    "\n",
    "timestamp = datetime.datetime(2021, 4, 2, 12, 28, 57)\n",
    "tMax = 60\n",
    "dt = 1\n",
    "tRange = tMax // dt\n",
    "plot_time_span = np.array([dt*i for i in range(tRange)])\n",
    "\n",
    "time_span = np.array([timestamp + datetime.timedelta(seconds=dt*i) for i in range(tRange)])\n",
    "\n",
    "\"\"\"\n",
    "Here we instantiate our transition and measurement models. These are the \n",
    "same models used in the StoneSoup Kalman Filter examples.\n",
    "\"\"\"\n",
    "\n",
    "q_x = 0.05\n",
    "q_y = 0.05\n",
    "sensor_x = 0  # Placing the sensor off-centre\n",
    "sensor_y = 0\n",
    "\n",
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(q_x),\n",
    "                                                          ConstantVelocity(q_y)])\n",
    "\n",
    "measurement_model = CartesianToBearingRange(\n",
    "ndim_state=4,\n",
    "mapping=(0, 2),\n",
    "noise_covar=np.diag([np.radians(1), 1]),  # Covariance matrix. 0.2 degree variance in\n",
    "# bearing and 1 metre in range\n",
    "translation_offset=np.array([[sensor_x], [sensor_y]])  # Offset measurements to location of\n",
    "# sensor in cartesian.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3c7b9-e997-4aab-a103-a504880da933",
   "metadata": {},
   "source": [
    "Now with our simulator we need to instantiate the Pytorch Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b76935-2e6b-46e2-9712-e3bb6fb1815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Datasets should be specified on a per simulation basis\n",
    "\n",
    "#class sequence_generator(Dataset):\n",
    "\n",
    "class dataset_2D_bearing_range(Dataset):\n",
    "    #Range Bearing 2D Dataset Sequence Packer\n",
    "\n",
    "    def __init__(self, dataset, ground_truth=None, measurements=None):\n",
    "        if dataset == None:   \n",
    "            gt = np.array([e.state_vector for e in ground_truth]).squeeze().T\n",
    "            gt = torch.tensor(gt.astype(dtype=np.float32),device = device)\n",
    "            ms = np.array([m.state_vector for m in measurements]).squeeze().T\n",
    "            ms = torch.tensor(ms.astype(dtype=np.float32),device = device)\n",
    "            self.dataset = torch.unsqueeze(torch.cat((ms,gt)),dim=0)\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "            \n",
    "    \n",
    "    def append_to_dataset(self, ground_truth, measurements):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ground_truth : :class:`~.list`\n",
    "            A list of Stonesoup States.\n",
    "        measurements : :class:`~.measurements`\n",
    "            The list of Stonesoup Measurements to be used.\n",
    "        \"\"\"\n",
    "    \n",
    "        gt = np.array([e.state_vector for e in ground_truth]).squeeze().T\n",
    "        gt = torch.tensor(gt.astype(dtype=np.float32),device = device)\n",
    "        ms = np.array([m.state_vector for m in measurements]).squeeze().T\n",
    "        ms = torch.tensor(ms.astype(dtype=np.float32),device = device)\n",
    "        new_entry = torch.cat((ms,gt),dim=0)\n",
    "\n",
    "        self.dataset = torch.cat((self.dataset,torch.unsqueeze(new_entry,dim=0)),dim=0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx,0:2].T, self.dataset[idx,2:6].T\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5f341-04aa-4f3f-b554-c01f40df6165",
   "metadata": {},
   "source": [
    "Now we need to simulate and add to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ce240c-0a77-4470-b1b1-5230d611b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Datasets should be specified on a per simulation basis\n",
    "# Should look up realistic values for radar precision and initial states\n",
    "# Come up with realistic constraints for initial velocities\n",
    "\n",
    "#class sequence_generator(Dataset):\n",
    "\n",
    "class dataset_composer():\n",
    "    #Range Bearing 2D Dataset Sequence Packer\n",
    "    def __init__(self, simulators, training_dataset, testing_dataset):\n",
    "        #pass a list of simulators\n",
    "        self.simulators = simulators\n",
    "        self.training_dataset = training_dataset\n",
    "        self.testing_dataset = testing_dataset\n",
    "\n",
    "    def simulate_trajectories(self, training_dataset_len, testing_ratio):\n",
    "        for simulator in self.simulators:\n",
    "            trainset_length = int((training_dataset_len-1) / len(self.simulators)) # Partition dataset into sets from each simulator\n",
    "            for i in range(trainset_length):\n",
    "                ground_truth, measurements = simulator.generate_training_data(time_span)\n",
    "                self.training_dataset.append_to_dataset(ground_truth, measurements)\n",
    "            trainloader = DataLoader(self.training_dataset)\n",
    "\n",
    "            testset_length = int(((training_dataset_len)*testing_ratio -1)/len(self.simulators))\n",
    "            for i in range(testset_length):\n",
    "                ground_truth, measurements = simulator.generate_training_data(time_span)\n",
    "                self.testing_dataset.append_to_dataset(ground_truth, measurements)\n",
    "            testloader = DataLoader(self.testing_dataset)\n",
    "        return trainloader, testloader\n",
    "\n",
    "    def output_to_file(self, trainset_name, testset_name):\n",
    "        torch.save(self.training_dataset, trainset_name)\n",
    "        torch.save(self.testing_dataset, testset_name)\n",
    "\n",
    "    def read_from_file(self, training_file_name, testing_file_name, device):\n",
    "        trn = torch.load(training_file_name, map_location = device)\n",
    "        tst = torch.load(testing_file_name, map_location = device)\n",
    "        return DataLoader(trn), DataLoader(tst)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3514489-8f13-464a-8c87-296cb40cf9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position, Velocity, Position, Velocity\n",
    "state_range_min = np.array([-25, -2, -25, -2])\n",
    "state_range_max = np.array([25, 2, 25, 2])\n",
    "\n",
    "# Add some sort of miniumum speed\n",
    "\n",
    "meas_range_min = np.array([0, 0])\n",
    "meas_range_max = np.array([0, 0])\n",
    "\n",
    "# Randomization for process noise\n",
    "process_noise_coefficients = [0.005, 0.05, 0.5]\n",
    "\n",
    "nonlinear_simulator = simulator(transition_model=transition_model,\n",
    "                      measurement_model=measurement_model,\n",
    "                      state_range = (state_range_min, state_range_max),\n",
    "                      meas_range = (meas_range_min, meas_range_max)\n",
    ")\n",
    "\n",
    "ground_truth, measurements = nonlinear_simulator.generate_training_data(time_span)\n",
    "training_dataset =  dataset_2D_bearing_range(dataset = None, ground_truth = ground_truth, measurements = measurements)\n",
    "testing_dataset =  dataset_2D_bearing_range(dataset = None, ground_truth = ground_truth, measurements = measurements)\n",
    "\n",
    "#training_dataset_len = 1000000 #  1,000,000\n",
    "training_dataset_len = 100000 #  100,000\n",
    "#training_dataset_len = 10000\n",
    "testing_ratio = 0.25\n",
    "\n",
    "dataset_composer = dataset_composer([nonlinear_simulator], testing_dataset, training_dataset)\n",
    "\n",
    "#trainloader, testloader = dataset_composer.simulate_trajectories(training_dataset_len, testing_ratio)\n",
    "#dataset_composer.output_to_file('training_data','testing_data')\n",
    "trainloader, testloader = dataset_composer.read_from_file('training_data', 'testing_data', device)\n",
    "#print('Training Dataset Length:', training_dataset.__len__())\n",
    "#print('Testing Dataset Length:',testing_dataset.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f298b99-0c26-4436-a6a3-bc227fd8b9fb",
   "metadata": {},
   "source": [
    "Turn Sequences into dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ad44e-5074-4c21-8bbe-7a2968ccc9f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf9492f-f6d9-4dba-b63d-390ca68b5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "nonlinearity = 'relu'\n",
    "output_size = 4\n",
    "\n",
    "class BiDirectionalRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, nonlinearity, num_layers, device):\n",
    "        super(BiDirectionalRNN, self).__init__()\n",
    "        self.RNN = torch.nn.RNN(input_size, hidden_size, bidirectional=True, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(2*hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, RNN_hidden):\n",
    "        RNN_output, RNN_hidden = self.RNN(input, RNN_hidden)\n",
    "        output = self.linear(RNN_output)\n",
    "        return output, RNN_hidden\n",
    "\n",
    "model = BiDirectionalRNN(input_size, hidden_size, output_size, nonlinearity, num_layers=num_layers, device=device)\n",
    "#model = EncoderDecoderRNN(input_size, hidden_size, output_size, num_layers=num_layers, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d4ce5-9a2e-4efd-972b-4a73124ee52d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985381c6-2a9f-435e-a58c-57de3ce79901",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.00005;\n",
    "weight_decay = 0.005 #L2 Regularization Factor\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a3363-ee43-4566-945f-a1df775924f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Training Loss: 938.8143310546875 \n",
      "Testing Loss: 750.7586669921875 \n",
      "---------------------------\n",
      "Epoch: 2 \n",
      "Training Loss: 560.3429565429688 \n",
      "Testing Loss: 563.3450927734375 \n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "RNN_hidden = torch.zeros((2, tMax, hidden_size),device=device)\n",
    "\n",
    "training_loss = torch.zeros(len(trainloader))\n",
    "testing_loss = torch.zeros(len(testloader))\n",
    "training_loss_epoch = torch.zeros(n_epochs)\n",
    "testing_loss_epoch = torch.zeros(n_epochs)\n",
    "testing_MSE = torch.zeros(1, tMax, output_size, device=device)\n",
    "for i in range(n_epochs):\n",
    "    for j, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs, encoder_hidden = model(inputs, RNN_hidden.detach())\n",
    "        train_loss = criterion(outputs, labels)\n",
    "        training_loss[j] = train_loss\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    training_loss_epoch[i] = torch.mean(train_loss).item()\n",
    "    with (torch.no_grad()):\n",
    "        for j, data in enumerate(testloader):\n",
    "            inputs, labels = data\n",
    "            outputs, encoder_hidden = model(inputs, RNN_hidden.detach())\n",
    "            test_loss = criterion(outputs, labels)\n",
    "            testing_loss[j] = test_loss\n",
    "        testing_loss_epoch[i] = torch.mean(testing_loss).item()\n",
    "\n",
    "    print(\"Epoch:\",i+1, \"\\nTraining Loss:\", training_loss_epoch[i].item(),\n",
    "          \"\\nTesting Loss:\", testing_loss_epoch[i].item(),\n",
    "          \"\\n---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efe313-64a7-47ce-9840-dfcacd5e5a75",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a2a3e-77c0-4611-91a7-c029fe85da1a",
   "metadata": {},
   "source": [
    "Trajectory MSE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4c174-f4cb-4486-936e-7ec66440f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "trajectory_mse_func = nn.MSELoss(reduction='none')\n",
    "with (torch.no_grad()):\n",
    "    j = 0\n",
    "    for j, data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "        outputs, encoder_hidden = model(inputs, RNN_hidden.detach())\n",
    "        trajectory_MSE += trajectory_mse_func(outputs.squeeze(), labels.squeeze())\n",
    "        j = j+1\n",
    "    testing_MSE = trajectory_MSE / j\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, RNN_combined_plot = plt.subplots(1,2)\n",
    "\n",
    "RNN_x = testing_MSE.T[0].cpu().numpy()\n",
    "RNN_xv = testing_MSE.T[1].cpu().numpy()\n",
    "RNN_y = testing_MSE.T[2].cpu().numpy()\n",
    "RNN_yv = testing_MSE.T[3].cpu().numpy()\n",
    "t = range(len(time_span))\n",
    "\n",
    "RNN_pos = np.sqrt( (RNN_x + RNN_y) / 2 )\n",
    "RNN_vel = np.sqrt( (RNN_xv + RNN_yv) / 2 )\n",
    "\n",
    "t = range(len(time_span))\n",
    "height = 3\n",
    "\n",
    "width = 9\n",
    "\n",
    "fig.tight_layout()\n",
    "RNN_combined_plot[0].plot(t, RNN_pos, color=\"C0\")\n",
    "RNN_combined_plot[0].set_xlabel(\"Time (s)\")\n",
    "RNN_combined_plot[0].set_ylabel(\"Root Mean Square Error (km)\")\n",
    "RNN_combined_plot[0].set_title(\"Avg RMSE vs Time\")\n",
    "RNN_combined_plot[0].figure.set_figwidth(width) # 6.4\n",
    "RNN_combined_plot[0].figure.set_figheight(height) # 6.4\n",
    "RNN_combined_plot[1].plot(t, RNN_vel, color=\"C1\")\n",
    "RNN_combined_plot[1].set_xlabel(\"Time (s)\")\n",
    "RNN_combined_plot[1].set_ylabel(\"Root Mean Square Error (km/s)\")\n",
    "RNN_combined_plot[1].set_title(\"Avg RMSE vs Time\")\n",
    "RNN_combined_plot[1].figure.set_figwidth(width) # 6.4\n",
    "RNN_combined_plot[1].figure.set_figheight(height) # 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc98432-5da8-492f-853b-6676dbb43984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a2593-88fb-4386-8fb6-e94b4a0abf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "x = range(n_epochs)\n",
    "\n",
    "ax[0].set_title(\"Training Loss (MSE)\")\n",
    "ax[0].plot(x, training_loss_epoch,color=\"C0\")\n",
    "fig.tight_layout()\n",
    "ax[1].set_title(\"Testing Loss (MSE)\")\n",
    "ax[1].plot(x, testing_loss_epoch,color=\"C1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aec527-11b9-4758-9863-33489235dff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6412046-f075-4fcf-ad67-3db3a740893b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a79d1e72-91bb-409c-98e7-dab000104b18",
   "metadata": {},
   "source": [
    "Track Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fd891-f007-4f65-868a-b085e5d40ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class track_simulator():\n",
    "    def __init__(self, predictor, updater, dataloader, time_span):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_model : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        measurement_model : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        \"\"\"\n",
    "        self.predictor = predictor\n",
    "        self.updater = updater\n",
    "        self.dataloader = dataloader\n",
    "        self.time_span = time_span\n",
    "\n",
    "    def initializer(self, time_stamp):\n",
    "        state_range_min = np.array([-25, -2, -25, -2])\n",
    "        state_range_max = np.array([25, 2, 25, 2])\n",
    "        state_vector = StateVector(np.random.uniform(low=state_range_min, high=state_range_max))\n",
    "        return GaussianState(state_vector = state_vector, covar = np.eye(4), timestamp=time_stamp)\n",
    "\n",
    "    def _simulate_track(self, input):\n",
    "        track = Track()\n",
    "        prior = self.initializer(self.time_span[0])\n",
    "        for i in range(inputs.shape[1]):\n",
    "            measurement = Detection(state_vector=input[0,i].cpu().numpy(), timestamp = self.time_span[i])\n",
    "            prediction = self.predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "            posterior = self.updater.update(SingleHypothesis(prediction, measurement))\n",
    "            track.append(posterior)\n",
    "            prior = track[-1]\n",
    "        tk = np.array([e.state_vector for e in track]).squeeze().T\n",
    "        tk = torch.tensor(tk.astype(dtype=np.float32),device = device)\n",
    "        return tk.T\n",
    "\n",
    "    def generate_MSE(self):\n",
    "        avg_loss = nn.MSELoss()\n",
    "        trajectory_MSE = nn.MSELoss(reduction='none')\n",
    "        MSE = torch.zeros(1,60,4, device=device) # Make this auto detect it\n",
    "        for j, data in enumerate(self.dataloader):\n",
    "            inputs, labels = data\n",
    "            outputs = self._simulate_track(inputs)\n",
    "            test_loss = avg_loss(outputs, labels.squeeze())\n",
    "            MSE += trajectory_MSE(outputs, labels.squeeze())\n",
    "            testing_loss[j] = test_loss\n",
    "        return torch.mean(testing_loss).numpy(), MSE.squeeze()/len(self.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf290af-e5c2-45e5-9fce-df06c7278e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ExtendedKalmanPredictor(transition_model)\n",
    "updater = ExtendedKalmanUpdater(measurement_model)\n",
    "\n",
    "track_simulator = track_simulator(predictor, updater, testloader, time_span)\n",
    "\n",
    "EKF_epoch_loss, EKF_track = track_simulator.generate_MSE()\n",
    "\n",
    "track_simulator.generate_MSE()\n",
    "\n",
    "epoch_mse, EKF_MSE = track_simulator.generate_MSE()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10021723-ea2c-40fc-9ccc-6cafe9038259",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2359d6-d880-48ab-baf9-2138c7074505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, EKF_mse_plot = plt.subplots(2,2)\n",
    "\n",
    "EKF_x = EKF_MSE.T[0].cpu().numpy()\n",
    "EKF_xv = EKF_MSE.T[1].cpu().numpy()\n",
    "EKF_y = EKF_MSE.T[2].cpu().numpy()\n",
    "EKF_yv = EKF_MSE.T[3].cpu().numpy()\n",
    "t = range(len(time_span))\n",
    "\n",
    "fig.tight_layout()\n",
    "EKF_mse_plot[0][0].plot(t, EKF_x, color=\"C0\")\n",
    "EKF_mse_plot[0][1].plot(t, EKF_xv, color=\"C1\")\n",
    "EKF_mse_plot[1][0].plot(t, EKF_y, color=\"C2\")\n",
    "EKF_mse_plot[1][1].plot(t, EKF_yv, color=\"C3\")\n",
    "#EKFmse[1].set_title(\"Testing Loss (MSE)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1537a-c383-4d27-95eb-75182d138076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, EKF_combined_plot = plt.subplots(1,2)\n",
    "\n",
    "EKF_x = EKF_MSE.T[0].cpu().numpy()\n",
    "EKF_xv = EKF_MSE.T[1].cpu().numpy()\n",
    "EKF_y = EKF_MSE.T[2].cpu().numpy()\n",
    "EKF_yv = EKF_MSE.T[3].cpu().numpy()\n",
    "t = range(len(time_span))\n",
    "\n",
    "EKF_pos = np.sqrt( (EKF_x + EKF_y) / 2 )\n",
    "EKF_vel = np.sqrt( (EKF_xv + EKF_yv) / 2 )\n",
    "\n",
    "t = range(len(time_span))\n",
    "height = 3\n",
    "\n",
    "\n",
    "width = 9\n",
    "\n",
    "fig.tight_layout()\n",
    "EKF_combined_plot[0].plot(t, EKF_pos, color=\"C0\")\n",
    "EKF_combined_plot[0].set_xlabel(\"Time (s)\")\n",
    "EKF_combined_plot[0].set_ylabel(\"Root Mean Square Error (km)\")\n",
    "EKF_combined_plot[0].set_title(\"Avg RMSE vs Time\")\n",
    "EKF_combined_plot[0].figure.set_figwidth(width) # 6.4\n",
    "EKF_combined_plot[0].figure.set_figheight(height) # 6.4\n",
    "EKF_combined_plot[1].plot(t, EKF_vel, color=\"C1\")\n",
    "EKF_combined_plot[1].set_xlabel(\"Time (s)\")\n",
    "EKF_combined_plot[1].set_ylabel(\"Root Mean Square Error (km/s)\")\n",
    "EKF_combined_plot[1].set_title(\"Avg RMSE vs Time\")\n",
    "EKF_combined_plot[1].figure.set_figwidth(width) # 6.4\n",
    "EKF_combined_plot[1].figure.set_figheight(height) # 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1edba1-ff3d-47e5-8e56-4244b785c21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
