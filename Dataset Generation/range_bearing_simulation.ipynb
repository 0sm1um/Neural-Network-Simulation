{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0baead1d-7b40-405b-bb4a-7efb950c6157",
   "metadata": {},
   "source": [
    "First we instantiate the simulator class we will use to generate our sequences. The Simulator handles all the particulars about the target being tracked. This simulation in particular is a Linear Time Invariant scenario of an object travelling at a constant velocity in two dimensions. However, it is being observed via a nonlinear measurement model.\n",
    "\n",
    "In particular it is a Bearing Range sensor positioned at the origin of the coordinate system. Measurements are collected as a 2 dimensional vector containing an angle, and a distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a91ec2-b74f-4154-8844-19d876af75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.groundtruth import GroundTruthPath, GroundTruthState\n",
    "from stonesoup.types.detection import Detection\n",
    "\n",
    "from stonesoup.types.track import Track\n",
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "\n",
    "class simulator():\n",
    "\n",
    "    def __init__(self, transition_model, measurement_model, state_range, meas_range = None, noise_range = None, meas_noise_range = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_model : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        measurement_model : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        \"\"\"\n",
    "        self.transition_model= transition_model\n",
    "        self.measurement_model = measurement_model\n",
    "        self.state_range = state_range\n",
    "        self.meas_range = meas_range\n",
    "        self.noise_range = noise_range\n",
    "        self.meas_noise_range = meas_noise_range\n",
    "\n",
    "    def _generate_ground_truth(self, prior, time_span):\n",
    "        \n",
    "        time_interval = time_span[1]-time_span[0]\n",
    "        ground_truth = GroundTruthPath([prior])\n",
    "        for k in range(1, len(time_span)):\n",
    "            ground_truth.append(GroundTruthState(\n",
    "                self.transition_model.function(ground_truth[k-1], noise=True, time_interval=time_interval),\n",
    "                timestamp=time_span[k-1]))\n",
    "        return ground_truth\n",
    "    \n",
    "    def _simulate_measurements(self, ground_truth):\n",
    "        #Simulate Measurements\n",
    "        measurements = []\n",
    "        for state in ground_truth:\n",
    "            measurement = self.measurement_model.function(state, noise=True)\n",
    "            measurements.append(Detection(measurement,\n",
    "                                          timestamp=state.timestamp,\n",
    "                                          measurement_model=self.measurement_model))\n",
    "        return measurements\n",
    "\n",
    "    def _initializer(self, time_stamp):\n",
    "        state_range_min = self.state_range[0]\n",
    "        state_range_max = self.state_range[1]\n",
    "        state_vector = StateVector(np.random.uniform(low=state_range_min, high=state_range_max))\n",
    "        while np.sqrt(state_vector[1]**2+state_vector[3]**2) < 0.15:\n",
    "            state_vector = StateVector(np.random.uniform(low=state_range_min, high=state_range_max))\n",
    "        meas_range_low = self.meas_range[0]\n",
    "        meas_range_max = self.meas_range[1]\n",
    "        self.measurement_model.translation_offset = np.random.uniform(low=meas_range_low, high=meas_range_max).reshape(len(meas_range_low),1)\n",
    "        #process_noise = \n",
    "        #self.transition_model. = np.randint(low=0,high=len(noise_range))\n",
    "        \n",
    "        return State(state_vector = state_vector, timestamp=time_stamp)\n",
    "\n",
    "    def generate_training_data(self, time_span):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ground_truth : :class:`~.GroundTruthPath`\n",
    "            StateMutableSequence type object used to store ground truth.\n",
    "        initial_state : :class:`~.State`\n",
    "            Initial state for the ground truth system. This MUST be a State,\n",
    "            not a State subclass, like GaussianState or EnsembleState.\n",
    "        prior : :class:`~.GaussianState` or :class:`~.EnsembleState`\n",
    "            Initial state prediction of tracking algorithm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        track : :class:`~.Track`\n",
    "            The Stone Soup track object which contains the list of updated \n",
    "            state predictions made by the tracking algorithm employed.\n",
    "        \"\"\"\n",
    "\n",
    "        #Simulate Measurements\n",
    "        initial_state = self._initializer(time_span[0])\n",
    "        ground_truth = self._generate_ground_truth(initial_state, time_span)\n",
    "        measurements = self._simulate_measurements(ground_truth)\n",
    "        \n",
    "        return ground_truth, measurements\n",
    "\n",
    "    def simulate_track(self, predictor, updater, initial_state, prior, time_span):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictor : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        updater : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        ground_truth : :class:`~.GroundTruthPath`\n",
    "            StateMutableSequence type object used to store ground truth.\n",
    "        initial_state : :class:`~.State`\n",
    "            Initial state for the ground truth system. This MUST be a State,\n",
    "            not a State subclass, like GaussianState or EnsembleState.\n",
    "        prior : :class:`~.GaussianState` or :class:`~.EnsembleState`\n",
    "            Initial state prediction of tracking algorithm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        track : :class:`~.Track`\n",
    "            The Stone Soup track object which contains the list of updated \n",
    "            state predictions made by the tracking algorithm employed.\n",
    "        \"\"\"\n",
    "\n",
    "        #Simulate Measurements\n",
    "        ground_truth = self._generate_ground_truth(initial_state, time_span)\n",
    "        measurements = self._simulate_measurements(ground_truth)\n",
    "        \n",
    "        #Initialize Loop Variables\n",
    "        track = Track()\n",
    "        for measurement in measurements:\n",
    "            prediction = predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "            hypothesis = SingleHypothesis(prediction, measurement)  # Group a prediction and measurement\n",
    "            posterior = updater.update(hypothesis)\n",
    "            track.append(posterior)\n",
    "            prior = track[-1]\n",
    "        return ground_truth, track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89b226e-0314-4d3b-ad70-5381641097e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "from stonesoup.types.array import StateVector, CovarianceMatrix\n",
    "from stonesoup.types.state import State, GaussianState\n",
    "\n",
    "from stonesoup.models.transition.linear import (CombinedLinearGaussianTransitionModel,\n",
    "                                                ConstantVelocity)\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n",
    "from stonesoup.updater.kalman import KalmanUpdater, ExtendedKalmanUpdater\n",
    "from stonesoup.predictor.ensemble import EnsemblePredictor\n",
    "from stonesoup.predictor.kalman import KalmanPredictor, ExtendedKalmanPredictor\n",
    "from stonesoup.models.measurement.nonlinear import CartesianToBearingRange\n",
    "\n",
    "\"\"\"\n",
    "    This script represents the code used to gather the data used in [PAPER HERE].\n",
    "    \n",
    "    This repository is structured such that different stone soup algorithms \n",
    "    can be run rapidly. Hopefully I've made it modular enough to \n",
    "    allow swapping of things like algorithms, and \"experiments\" by replacing\n",
    "    the desired transition and measurement models.\n",
    "    \n",
    "    The simulator class requires a transition and \n",
    "    measurement model, then the simulate_track method accepts a Stone Soup\n",
    "    Predictor, Updater, ground truth initial state, initial state for the\n",
    "    chosen algorithm, and a span of time which the simulation takes place over.\n",
    "    This time span should be an evenly spaced datetime.datetime list.\n",
    "    \n",
    "    The simulator then, is used to gather \"Track\" instances, and with a list \n",
    "    of tracks, RMSE can then be calculated.\n",
    "\"\"\"\n",
    "\n",
    "i = 60\n",
    "num_vectors = i*5\n",
    "\n",
    "\"\"\"\n",
    "    Here, we get our initial variables for simulation. For this, we are just\n",
    "    using a time span of 60 time instances spaced one second apart.\n",
    "\"\"\"\n",
    "\n",
    "timestamp = datetime.datetime(2021, 4, 2, 12, 28, 57)\n",
    "tMax = 30\n",
    "dt = 1\n",
    "tRange = tMax // dt\n",
    "plot_time_span = np.array([dt*i for i in range(tRange)])\n",
    "\n",
    "time_span = np.array([timestamp + datetime.timedelta(seconds=dt*i) for i in range(tRange)])\n",
    "\n",
    "\"\"\"\n",
    "Here we instantiate our transition and measurement models. These are the \n",
    "same models used in the StoneSoup Kalman Filter examples.\n",
    "\"\"\"\n",
    "\n",
    "q_x = 0.05\n",
    "q_y = 0.05\n",
    "sensor_x = 0  # Placing the sensor off-centre\n",
    "sensor_y = 0\n",
    "\n",
    "transition_model = CombinedLinearGaussianTransitionModel([ConstantVelocity(q_x),\n",
    "                                                          ConstantVelocity(q_y)])\n",
    "\n",
    "measurement_model = CartesianToBearingRange(\n",
    "ndim_state=4,\n",
    "mapping=(0, 2),\n",
    "noise_covar=np.diag([np.radians(1)**2, 0.1**2]),  # Covariance matrix. 0.2 degree variance in\n",
    "# bearing and 1 metre in range\n",
    "translation_offset=np.array([[sensor_x], [sensor_y]])  # Offset measurements to location of\n",
    "# sensor in cartesian.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3c7b9-e997-4aab-a103-a504880da933",
   "metadata": {},
   "source": [
    "In order to use this simulated data, we need to format it such that it can be loaded into PyTorch easily. Pytorch requires us to specify functions \"__get_item__\" and \"__len__\" in order to be usable by the generic Data Loader. I simply included the init and a helper function to append trajectories to the dataset for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b76935-2e6b-46e2-9712-e3bb6fb1815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Datasets should be specified on a per simulation basis\n",
    "\n",
    "#class sequence_generator(Dataset):\n",
    "\n",
    "class dataset_2D_bearing_range(Dataset):\n",
    "    #Range Bearing 2D Dataset Sequence Packer\n",
    "\n",
    "    def __init__(self, dataset, ground_truth=None, measurements=None):\n",
    "        if dataset == None:   \n",
    "            gt = np.array([e.state_vector for e in ground_truth]).squeeze().T\n",
    "            gt = torch.tensor(gt.astype(dtype=np.float32),device = device)\n",
    "            ms = np.array([m.state_vector for m in measurements]).squeeze().T\n",
    "            ms = torch.tensor(ms.astype(dtype=np.float32),device = device)\n",
    "            self.dataset = torch.unsqueeze(torch.cat((ms,gt)),dim=0)\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "            \n",
    "    \n",
    "    def append_to_dataset(self, ground_truth, measurements):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ground_truth : :class:`~.list`\n",
    "            A list of Stonesoup States.\n",
    "        measurements : :class:`~.measurements`\n",
    "            The list of Stonesoup Measurements to be used.\n",
    "        \"\"\"\n",
    "    \n",
    "        gt = np.array([e.state_vector for e in ground_truth]).squeeze().T\n",
    "        gt = torch.tensor(gt.astype(dtype=np.float32),device = device)\n",
    "        ms = np.array([m.state_vector for m in measurements]).squeeze().T\n",
    "        ms = torch.tensor(ms.astype(dtype=np.float32),device = device)\n",
    "        new_entry = torch.cat((ms,gt),dim=0)\n",
    "\n",
    "        self.dataset = torch.cat((self.dataset,torch.unsqueeze(new_entry,dim=0)),dim=0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx,0:2].T, self.dataset[idx,2:6].T\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5f341-04aa-4f3f-b554-c01f40df6165",
   "metadata": {},
   "source": [
    "This next module is something I call the Composer. The Composer's job is to return a useful dataset for use in PyTorch, and I will tell it how many trajectories I want, and it will call the relevant simulator and dataset methods to generate a dataset for the purpose of learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ce240c-0a77-4470-b1b1-5230d611b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Datasets should be specified on a per simulation basis\n",
    "# Should look up realistic values for radar precision and initial states\n",
    "# Come up with realistic constraints for initial velocities\n",
    "\n",
    "#class sequence_generator(Dataset):\n",
    "\n",
    "class dataset_composer():\n",
    "    #Range Bearing 2D Dataset Sequence Packer\n",
    "    def __init__(self, simulators, training_dataset, testing_dataset, batch_size, num_workers):\n",
    "        #pass a list of simulators\n",
    "        self.simulators = simulators\n",
    "        self.training_dataset = training_dataset\n",
    "        self.testing_dataset = testing_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def simulate_trajectories(self, training_dataset_len, testing_ratio):\n",
    "        for simulator in self.simulators:\n",
    "            trainset_length = int((training_dataset_len-1) / len(self.simulators)) # Partition dataset into sets from each simulator\n",
    "            for i in range(trainset_length):\n",
    "                ground_truth, measurements = simulator.generate_training_data(time_span)\n",
    "                self.training_dataset.append_to_dataset(ground_truth, measurements)\n",
    "            trainloader = DataLoader(self.training_dataset)\n",
    "\n",
    "            testset_length = int(((training_dataset_len)*testing_ratio -1)/len(self.simulators))\n",
    "            for i in range(testset_length):\n",
    "                ground_truth, measurements = simulator.generate_training_data(time_span)\n",
    "                self.testing_dataset.append_to_dataset(ground_truth, measurements)\n",
    "            testloader = DataLoader(self.testing_dataset)\n",
    "        return trainloader, testloader\n",
    "\n",
    "    def output_to_file(self, trainset_name, testset_name):\n",
    "        torch.save(self.training_dataset, trainset_name)\n",
    "        torch.save(self.testing_dataset, testset_name)\n",
    "\n",
    "    def read_from_file(self, training_file_name, testing_file_name, device):\n",
    "        trn = torch.load(training_file_name, map_location = device)\n",
    "        tst = torch.load(testing_file_name, map_location = device)\n",
    "        return DataLoader(trn, batch_size = self.batch_size, num_workers=self.num_workers), DataLoader(tst, batch_size = self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503acaa-e633-4dbf-b51f-2123301dd2c4",
   "metadata": {},
   "source": [
    "Here we instantiate the simulator, provide a range of permissable values for the initial conditions, noise coefficients, and specify the transition model, and measurement model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3514489-8f13-464a-8c87-296cb40cf9f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Position, Velocity, Position, Velocity\n",
    "state_range_min = np.array([-15, -2, -15, -2])\n",
    "state_range_max = np.array([15, 2, 15, 2])\n",
    "\n",
    "# Add some sort of miniumum speed\n",
    "\n",
    "meas_range_min = np.array([0, 0])\n",
    "meas_range_max = np.array([0, 0])\n",
    "\n",
    "# Randomization for process noise\n",
    "#process_noise_coefficients = [0.005, 0.05, 0.5]\n",
    "process_noise_coefficients = [0.05]\n",
    "\n",
    "nonlinear_simulator = simulator(transition_model=transition_model,\n",
    "                      measurement_model=measurement_model,\n",
    "                      state_range = (state_range_min, state_range_max),\n",
    "                      meas_range = (meas_range_min, meas_range_max)\n",
    ")\n",
    "\n",
    "ground_truth, measurements = nonlinear_simulator.generate_training_data(time_span)\n",
    "training_dataset =  dataset_2D_bearing_range(dataset = None, ground_truth = ground_truth, measurements = measurements)\n",
    "testing_dataset =  dataset_2D_bearing_range(dataset = None, ground_truth = ground_truth, measurements = measurements)\n",
    "\n",
    "#training_dataset_len = 1000000 #  1,000,000\n",
    "training_dataset_len = 100000 #  100,000\n",
    "#training_dataset_len = 10000\n",
    "testing_ratio = 0.15\n",
    "\n",
    "#batch_size = int(2**7) # 128\n",
    "#batch_size = int(2**6) # 64\n",
    "#batch_size = int(2**5) # 32\n",
    "batch_size = int(2**5)\n",
    "num_workers = 0\n",
    "\n",
    "dataset_composer = dataset_composer([nonlinear_simulator], testing_dataset, training_dataset, batch_size = batch_size, num_workers = num_workers)\n",
    "\n",
    "#trainloader, testloader = dataset_composer.simulate_trajectories(training_dataset_len, testing_ratio)\n",
    "#dataset_composer.output_to_file('training_data','testing_data')\n",
    "trainloader, testloader = dataset_composer.read_from_file('training_data', 'testing_data', device)\n",
    "#print('Training Dataset Length:', training_dataset.__len__())\n",
    "#print('Testing Dataset Length:',testing_dataset.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f298b99-0c26-4436-a6a3-bc227fd8b9fb",
   "metadata": {},
   "source": [
    "Turn Sequences into dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ad44e-5074-4c21-8bbe-7a2968ccc9f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf9492f-f6d9-4dba-b63d-390ca68b5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "nonlinearity = 'relu'\n",
    "output_size = 4\n",
    "\n",
    "class UniDirectionalRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, nonlinearity, num_layers, device):\n",
    "        super(UniDirectionalRNN, self).__init__()\n",
    "        self.RNN = torch.nn.RNN(input_size, hidden_size, bidirectional=False, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, RNN_hidden):\n",
    "        RNN_output, RNN_hidden = self.RNN(input, RNN_hidden)\n",
    "        output = self.linear(RNN_output)\n",
    "        return output, RNN_hidden\n",
    "\n",
    "class BiDirectionalRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, nonlinearity, num_layers, device):\n",
    "        super(BiDirectionalRNN, self).__init__()\n",
    "        self.RNN = torch.nn.RNN(input_size, hidden_size, bidirectional=True, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(2*hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, RNN_hidden):\n",
    "        RNN_output, RNN_hidden = self.RNN(input, RNN_hidden)\n",
    "        output = self.linear(RNN_output)\n",
    "        return output, RNN_hidden\n",
    "\n",
    "class BiDirectionalLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, device):\n",
    "        super(BiDirectionalLSTM, self).__init__()\n",
    "        self.LSTM = torch.nn.LSTM(input_size, hidden_size, bidirectional=True, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(2*hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, LSTM_hidden, LSTM_cell):\n",
    "        LSTM_output, (LSTM_hidden, LSTM_cell) = self.LSTM(input, (LSTM_hidden, LSTM_cell))\n",
    "        output = self.linear(LSTM_output)\n",
    "        return output, (LSTM_hidden, LSTM_cell)\n",
    "\n",
    "class UniDirectionalLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, device):\n",
    "        super(UniDirectionalLSTM, self).__init__()\n",
    "        self.LSTM = torch.nn.LSTM(input_size, hidden_size, bidirectional=False, num_layers=num_layers, device=device)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input, LSTM_hidden, LSTM_cell):\n",
    "        LSTM_output, (LSTM_hidden, LSTM_cell) = self.LSTM(input, (LSTM_hidden, LSTM_cell))\n",
    "        output = self.linear(LSTM_output)\n",
    "        return output, (LSTM_hidden, LSTM_cell)\n",
    "\n",
    "class MHATransformer(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=16, output_size = 4, nhead=4, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, device=None):\n",
    "        super(MHATransformer, self).__init__()\n",
    "        self.input_layer = torch.nn.Linear(input_size, hidden_size, device=device)\n",
    "        self.transformer = torch.nn.Transformer(d_model=hidden_size, nhead=nhead,\n",
    "                                                num_encoder_layers=num_encoder_layers,\n",
    "                                                num_decoder_layers=num_decoder_layers,\n",
    "                                                dim_feedforward=dim_feedforward,\n",
    "                                                batch_first=True,\n",
    "                                                device=device)\n",
    "        self.output_layer = torch.nn.Linear(hidden_size, output_size, device=device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden_input = self.input_layer(input)\n",
    "        transformer_output = self.transformer(hidden_input, hidden_input)\n",
    "        return self.output_layer(transformer_output)\n",
    "\n",
    "UniRNN = UniDirectionalRNN(input_size=2, hidden_size=32, output_size=4, nonlinearity=nonlinearity, num_layers=1, device=device)\n",
    "BiRNN = BiDirectionalRNN(input_size=2, hidden_size=32, output_size=4, nonlinearity=nonlinearity, num_layers=1, device=device)\n",
    "UniLSTM = UniDirectionalLSTM(input_size=2, hidden_size=32, output_size=4, num_layers=1, device=device)\n",
    "BiLSTM = BiDirectionalLSTM(input_size=2, hidden_size=32, output_size=4, num_layers=1, device=device)\n",
    "Transformer = MHATransformer(input_size=2, hidden_size = 32, output_size = 4, nhead=16, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d4ce5-9a2e-4efd-972b-4a73124ee52d",
   "metadata": {},
   "source": [
    "Initialize Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985381c6-2a9f-435e-a58c-57de3ce79901",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "UniRNN_learning_rate = 0.000005;\n",
    "UniRNN_weight_decay = 0.000 #L2 Regularization Factor\n",
    "UniRNN_optimizer = torch.optim.Adam(UniRNN.parameters(),lr=UniRNN_learning_rate, weight_decay = UniRNN_weight_decay)\n",
    "\n",
    "BiRNN_learning_rate = 0.000005;\n",
    "BiRNN_weight_decay = 0.000 #L2 Regularization Factor\n",
    "BiRNN_optimizer = torch.optim.Adam(BiRNN.parameters(),lr=BiRNN_learning_rate, weight_decay = BiRNN_learning_rate)\n",
    "\n",
    "UniLSTM_learning_rate = 0.000005;\n",
    "UniLSTM_weight_decay = 0.000 #L2 Regularization Factor\n",
    "UniLSTM_optimizer = torch.optim.Adam(UniLSTM.parameters(),lr=UniLSTM_learning_rate, weight_decay = UniLSTM_weight_decay)\n",
    "\n",
    "BiLSTM_learning_rate = 0.000005;\n",
    "BiLSTM_weight_decay = 0.000 #L2 Regularization Factor\n",
    "BiLSTM_optimizer = torch.optim.Adam(BiLSTM.parameters(),lr=BiLSTM_learning_rate, weight_decay = BiLSTM_weight_decay)\n",
    "\n",
    "TransformerLearning_rate = 0.000005;\n",
    "TransformerWeight_decay = 0.000 #L2 Regularization Factor\n",
    "Transformer_optimizer = torch.optim.Adam(Transformer.parameters(),lr=TransformerLearning_rate, weight_decay = TransformerWeight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214fb703-df50-4988-b69c-9bfa2041e242",
   "metadata": {},
   "source": [
    "Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a3363-ee43-4566-945f-a1df775924f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------- \n",
      "-----      Epoch : 1         -----  Train Loss :  Test Loss -----\n",
      "-----  UniDirectional RNN:   -----    281.225  :   279.776  -----\n",
      "-----   BiDirectional RNN:   -----    280.694  :   278.903  -----\n",
      "-----  UniDirectional LSTM:  -----    281.237  :   279.971  -----\n",
      "-----  BiDirectional LSTM:   -----    281.330  :   279.976  -----\n",
      "-----      Transformer:      -----    245.546  :   236.088  -----\n",
      "----------------------------------------------------------------- \n",
      "-----      Epoch : 2         -----  Train Loss :  Test Loss -----\n",
      "-----  UniDirectional RNN:   -----    280.776  :   279.268  -----\n",
      "-----   BiDirectional RNN:   -----    279.562  :   277.707  -----\n",
      "-----  UniDirectional LSTM:  -----    280.999  :   279.689  -----\n",
      "-----  BiDirectional LSTM:   -----    281.044  :   279.615  -----\n",
      "-----      Transformer:      -----    233.278  :   228.259  -----\n",
      "----------------------------------------------------------------- \n",
      "-----      Epoch : 3         -----  Train Loss :  Test Loss -----\n",
      "-----  UniDirectional RNN:   -----    280.211  :   278.693  -----\n",
      "-----   BiDirectional RNN:   -----    278.285  :   276.414  -----\n",
      "-----  UniDirectional LSTM:  -----    280.727  :   279.407  -----\n",
      "-----  BiDirectional LSTM:   -----    280.605  :   279.115  -----\n",
      "-----      Transformer:      -----    225.882  :   221.181  -----\n",
      "----------------------------------------------------------------- \n",
      "-----      Epoch : 4         -----  Train Loss :  Test Loss -----\n",
      "-----  UniDirectional RNN:   -----    279.549  :   277.989  -----\n",
      "-----   BiDirectional RNN:   -----    276.894  :   274.965  -----\n",
      "-----  UniDirectional LSTM:  -----    280.386  :   278.997  -----\n",
      "-----  BiDirectional LSTM:   -----    279.971  :   278.365  -----\n",
      "-----      Transformer:      -----    218.854  :   214.189  -----\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "UniRNN_hidden = torch.zeros((1, tMax, hidden_size),device=device)\n",
    "\n",
    "BiRNN_hidden = torch.zeros((2, tMax, hidden_size),device=device)\n",
    "\n",
    "UniLSTM_hidden = torch.zeros((1, tMax, hidden_size),device=device)\n",
    "UniLSTM_cell = torch.zeros((1, tMax, hidden_size),device=device)\n",
    "\n",
    "BiLSTM_hidden = torch.zeros((2, tMax, hidden_size),device=device)\n",
    "BiLSTM_cell = torch.zeros((2, tMax, hidden_size),device=device)\n",
    "\n",
    "UniRNN_training_loss_epoch = np.zeros(n_epochs)\n",
    "BiRNN_training_loss_epoch = np.zeros(n_epochs)\n",
    "UniLSTM_training_loss_epoch = np.zeros(n_epochs)\n",
    "BiLSTM_training_loss_epoch = np.zeros(n_epochs)\n",
    "Transformer_training_loss_epoch = np.zeros(n_epochs)\n",
    "\n",
    "UniRNN_testing_loss_epoch = np.zeros(n_epochs)\n",
    "BiRNN_testing_loss_epoch = np.zeros(n_epochs)\n",
    "UniLSTM_testing_loss_epoch = np.zeros(n_epochs)\n",
    "BiLSTM_testing_loss_epoch = np.zeros(n_epochs)\n",
    "Transformer_testing_loss_epoch = np.zeros(n_epochs)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for j, data in enumerate(trainloader):        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        UniRNN_optimizer.zero_grad()\n",
    "        BiRNN_optimizer.zero_grad()\n",
    "        UniLSTM_optimizer.zero_grad()\n",
    "        BiLSTM_optimizer.zero_grad()\n",
    "        Transformer_optimizer.zero_grad()\n",
    "        \n",
    "        UniRNN_outputs, UniRNN_hidden = UniRNN(inputs, UniRNN_hidden.detach())\n",
    "        BiRNN_outputs, BiRNN_hidden = BiRNN(inputs, BiRNN_hidden.detach())\n",
    "        UniLSTM_outputs, (UniLSTM_hidden, UniLSTM_cell) = UniLSTM(inputs, UniLSTM_hidden.detach(), UniLSTM_cell.detach())\n",
    "        BiLSTM_outputs, (BiLSTM_hidden, BiLSTM_cell) = BiLSTM(inputs, BiLSTM_hidden.detach(), BiLSTM_cell.detach())\n",
    "        Transformer_outputs = Transformer(inputs)\n",
    "        \n",
    "        UniRNN_train_loss = criterion(UniRNN_outputs, labels)\n",
    "        BiRNN_train_loss = criterion(BiRNN_outputs, labels)\n",
    "        UniLSTM_train_loss = criterion(UniLSTM_outputs, labels)\n",
    "        BiLSTM_train_loss = criterion(BiLSTM_outputs, labels)\n",
    "        Transformer_train_loss = criterion(Transformer_outputs, labels)\n",
    "\n",
    "        UniRNN_training_loss_epoch[i] += UniRNN_train_loss.item()\n",
    "        BiRNN_training_loss_epoch[i] += BiRNN_train_loss.item()\n",
    "        UniLSTM_training_loss_epoch[i] += UniLSTM_train_loss.item()\n",
    "        BiLSTM_training_loss_epoch[i] += BiLSTM_train_loss.item()\n",
    "        Transformer_training_loss_epoch[i] += Transformer_train_loss.item()\n",
    "\n",
    "        UniRNN_train_loss.backward()\n",
    "        BiRNN_train_loss.backward()\n",
    "        UniLSTM_train_loss.backward()\n",
    "        BiLSTM_train_loss.backward()\n",
    "        Transformer_train_loss.backward()\n",
    "        \n",
    "        UniRNN_optimizer.step()\n",
    "        BiRNN_optimizer.step()\n",
    "        UniLSTM_optimizer.step()\n",
    "        BiLSTM_optimizer.step()\n",
    "        Transformer_optimizer.step()\n",
    "\n",
    "    UniRNN_training_loss_epoch[i] = UniRNN_training_loss_epoch[i] / (j+1)\n",
    "    BiRNN_training_loss_epoch[i] = BiRNN_training_loss_epoch[i] / (j+1)\n",
    "    UniLSTM_training_loss_epoch[i] = UniLSTM_training_loss_epoch[i] / (j+1)\n",
    "    BiLSTM_training_loss_epoch[i] = BiLSTM_training_loss_epoch[i] / (j+1)\n",
    "    Transformer_training_loss_epoch[i] = Transformer_training_loss_epoch[i] / (j+1)\n",
    "\n",
    "    with (torch.no_grad()):\n",
    "        for j, data in enumerate(testloader):            \n",
    "            inputs, labels = data\n",
    "            \n",
    "            UniRNN_outputs, UniRNN_hidden = UniRNN(inputs, UniRNN_hidden.detach())\n",
    "            BiRNN_outputs, BiRNN_hidden = BiRNN(inputs, BiRNN_hidden.detach())\n",
    "            UniLSTM_outputs, (UniLSTM_hidden, UniLSTM_cell) = UniLSTM(inputs, UniLSTM_hidden.detach(), UniLSTM_cell.detach())\n",
    "            BiLSTM_outputs, (BiLSTM_hidden, BiLSTM_cell) = BiLSTM(inputs, BiLSTM_hidden.detach(), BiLSTM_cell.detach())\n",
    "            Transformer_outputs = Transformer(inputs)\n",
    "            \n",
    "            UniRNN_test_loss = criterion(UniRNN_outputs, labels)\n",
    "            BiRNN_test_loss = criterion(BiRNN_outputs, labels)\n",
    "            UniLSTM_test_loss = criterion(UniLSTM_outputs, labels)\n",
    "            BiLSTM_test_loss = criterion(BiLSTM_outputs, labels)\n",
    "            Transformer_test_loss = criterion(Transformer_outputs, labels)\n",
    "\n",
    "            UniRNN_testing_loss_epoch[i] += UniRNN_test_loss.item()\n",
    "            BiRNN_testing_loss_epoch[i] += BiRNN_test_loss.item()\n",
    "            UniLSTM_testing_loss_epoch[i] += UniLSTM_test_loss.item()\n",
    "            BiLSTM_testing_loss_epoch[i] += BiLSTM_test_loss.item()\n",
    "            Transformer_testing_loss_epoch[i] += Transformer_test_loss.item()\n",
    "        \n",
    "        UniRNN_testing_loss_epoch[i] = UniRNN_testing_loss_epoch[i]  / (j+1)\n",
    "        BiRNN_testing_loss_epoch[i] = BiRNN_testing_loss_epoch[i] / (j+1)\n",
    "        UniLSTM_testing_loss_epoch[i] = UniLSTM_testing_loss_epoch[i] / (j+1)\n",
    "        BiLSTM_testing_loss_epoch[i] = BiLSTM_testing_loss_epoch[i] / (j+1)\n",
    "        Transformer_testing_loss_epoch[i] = Transformer_testing_loss_epoch[i] / (j+1)\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\",\n",
    "          \"\\n-----      Epoch :\",i+1, \"        -----\",\n",
    "          \" Train Loss :  Test Loss -----\")\n",
    "    print(\"-----  UniDirectional RNN:   -----\",\n",
    "          \"{:10.3f}\".format(UniRNN_training_loss_epoch[i].item()) +'  :'+\"{:10.3f}\".format(UniRNN_testing_loss_epoch[i].item())+'  -----')\n",
    "    print(\"-----   BiDirectional RNN:   -----\",\n",
    "          \"{:10.3f}\".format(BiRNN_training_loss_epoch[i].item()) +'  :'+\"{:10.3f}\".format(BiRNN_testing_loss_epoch[i].item())+'  -----')\n",
    "    print(\"-----  UniDirectional LSTM:  -----\",\n",
    "          \"{:10.3f}\".format(UniLSTM_training_loss_epoch[i].item()) +'  :'+\"{:10.3f}\".format(UniLSTM_testing_loss_epoch[i].item())+'  -----')\n",
    "    print(\"-----  BiDirectional LSTM:   -----\",\n",
    "          \"{:10.3f}\".format(BiLSTM_training_loss_epoch[i].item()) +'  :'+\"{:10.3f}\".format(BiLSTM_testing_loss_epoch[i].item())+'  -----')\n",
    "    print(\"-----      Transformer:      -----\",\n",
    "          \"{:10.3f}\".format(Transformer_training_loss_epoch[i].item()) +'  :'+\"{:10.3f}\".format(Transformer_testing_loss_epoch[i].item())+'  -----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efe313-64a7-47ce-9840-dfcacd5e5a75",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a2a3e-77c0-4611-91a7-c029fe85da1a",
   "metadata": {},
   "source": [
    "Trajectory MSE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4c174-f4cb-4486-936e-7ec66440f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_mse_func = nn.MSELoss(reduction='none')\n",
    "tst = torch.load('testing_data', map_location = device)\n",
    "testloader = DataLoader(tst)\n",
    "\n",
    "UniRNN_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "BiRNN_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "UniLSTM_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "BiLSTM_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "Transformer_trajectory_MSE = torch.zeros(tMax, output_size, device=device)\n",
    "\n",
    "with (torch.no_grad()):\n",
    "    for j, data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        UniRNN_outputs, UniRNN_hidden = UniRNN(inputs, UniRNN_hidden.detach())\n",
    "        BiRNN_outputs, BiRNN_hidden = BiRNN(inputs, BiRNN_hidden.detach())\n",
    "        UniLSTM_outputs, (UniLSTM_hidden, UniLSTM_cell) = UniLSTM(inputs, UniLSTM_hidden.detach(), UniLSTM_cell.detach())\n",
    "        BiLSTM_outputs, (BiLSTM_hidden, BiLSTM_cell) = BiLSTM(inputs, BiLSTM_hidden.detach(), BiLSTM_cell.detach())\n",
    "        Transformer_outputs = Transformer(inputs)\n",
    "        \n",
    "        UniRNN_test_loss = criterion(UniRNN_outputs, labels)\n",
    "        BiRNN_test_loss = criterion(BiRNN_outputs, labels)\n",
    "        UniLSTM_test_loss = criterion(UniLSTM_outputs, labels)\n",
    "        BiLSTM_test_loss = criterion(BiLSTM_outputs, labels)\n",
    "        Transformer_test_loss = criterion(Transformer_outputs, labels)\n",
    "\n",
    "        UniRNN_trajectory_MSE += trajectory_mse_func(UniRNN_outputs.squeeze(), labels.squeeze())\n",
    "        BiRNN_trajectory_MSE += trajectory_mse_func(BiRNN_outputs.squeeze(), labels.squeeze())\n",
    "        UniLSTM_trajectory_MSE += trajectory_mse_func(UniLSTM_outputs.squeeze(), labels.squeeze())\n",
    "        BiLSTM_trajectory_MSE += trajectory_mse_func(BiLSTM_outputs.squeeze(), labels.squeeze())\n",
    "        Transformer_trajectory_MSE += trajectory_mse_func(Transformer_outputs.squeeze(), labels.squeeze())\n",
    "\n",
    "    UniRNN_testing_MSE = UniRNN_trajectory_MSE / j\n",
    "    BiRNN_testing_MSE = BiRNN_trajectory_MSE / j\n",
    "    UniLSTM_testing_MSE = UniLSTM_trajectory_MSE / j\n",
    "    BiLSTM_testing_MSE = BiLSTM_trajectory_MSE / j\n",
    "    Transformer_testing_MSE = Transformer_trajectory_MSE / j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d1e72-91bb-409c-98e7-dab000104b18",
   "metadata": {},
   "source": [
    "This Plotter class contains all of the info to generate the plots used in the paper. Each method accepts it's own standardized input and handles any data preprocessing internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f50a9-f6cc-4f8a-b241-af7b992722e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class plotter():\n",
    "    def __init__(self):\n",
    "        a = 'Hello World'\n",
    "\n",
    "    def avg_loss_vs_epoch(self, testing_loss):\n",
    "        return 0\n",
    "        \n",
    "    def two_by_one_MSE_vs_time(self, MSE_list, legend_list):\n",
    "        fig, MSE_combined_plot = plt.subplots(1,2)\n",
    "\n",
    "        height = 3\n",
    "        width = 9\n",
    "        \n",
    "        MSE_combined_plot[0].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[0].set_ylabel(\"Root Mean Square Error (km)\")\n",
    "        MSE_combined_plot[0].set_title(\"Avg RMSE in Position vs Time\")\n",
    "        MSE_combined_plot[0].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[0].figure.set_figheight(height) # 6.4\n",
    "        MSE_combined_plot[1].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[1].set_ylabel(\"Root Mean Square Error (km/s)\")\n",
    "        MSE_combined_plot[1].set_title(\"Avg RMSE in Velocity vs Time\")\n",
    "        MSE_combined_plot[1].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[1].figure.set_figheight(height) # 6.4\n",
    "        fig.tight_layout()\n",
    "\n",
    "        t = range(len(time_span))\n",
    "        i = 0\n",
    "        for MSE in MSE_list:\n",
    "            MSE_x = MSE.T[0].cpu().numpy()\n",
    "            MSE_xv = MSE.T[1].cpu().numpy()\n",
    "            MSE_y = MSE.T[2].cpu().numpy()\n",
    "            MSE_yv = MSE.T[3].cpu().numpy()\n",
    "\n",
    "            MSE_pos = np.sqrt( (MSE_x + MSE_y) / 2 )\n",
    "            MSE_vel = np.sqrt( (MSE_xv + MSE_yv) / 2 )\n",
    "\n",
    "            MSE_combined_plot[0].plot(t, MSE_pos)\n",
    "            MSE_combined_plot[1].plot(t, MSE_vel)\n",
    "            MSE_combined_plot[1].legend([legend_list[i]])\n",
    "            i += 1\n",
    "\n",
    "    def two_by_two_MSE_vs_time(self, MSE_list, legend_list):\n",
    "        fig, MSE_combined_plot = plt.subplots(2,2)\n",
    "        scale_factor = 1.5\n",
    "        height = 6 * scale_factor\n",
    "        width = 9 * scale_factor\n",
    "        \n",
    "        MSE_combined_plot[0][0].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[0][0].set_ylabel(\"Root Mean Square Error (km)\")\n",
    "        MSE_combined_plot[0][0].set_title(\"Avg RMSE in Horizontal Position vs Time\")\n",
    "        MSE_combined_plot[0][0].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[0][0].figure.set_figheight(height) # 6.4\n",
    "        \n",
    "        MSE_combined_plot[1][0].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[1][0].set_ylabel(\"Root Mean Square Error (km)\")\n",
    "        MSE_combined_plot[1][0].set_title(\"Avg RMSE in Vertical Position vs Time\")\n",
    "        MSE_combined_plot[1][0].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[1][0].figure.set_figheight(height) # 6.4\n",
    "\n",
    "        MSE_combined_plot[0][1].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[0][1].set_ylabel(\"Root Mean Square Error (km/s)\")\n",
    "        MSE_combined_plot[0][1].set_title(\"Avg RMSE in Horizontal Velocity vs Time\")\n",
    "        MSE_combined_plot[0][1].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[0][1].figure.set_figheight(height) # 6.4\n",
    "        \n",
    "        MSE_combined_plot[1][1].set_xlabel(\"Time (s)\")\n",
    "        MSE_combined_plot[1][1].set_ylabel(\"Root Mean Square Error (km/s)\")\n",
    "        MSE_combined_plot[1][1].set_title(\"Avg RMSE in Vertical Velocity vs Time\")\n",
    "        MSE_combined_plot[1][1].figure.set_figwidth(width) # 6.4\n",
    "        MSE_combined_plot[1][1].figure.set_figheight(height) # 6.4\n",
    "        fig.tight_layout()\n",
    "\n",
    "        t = range(len(time_span))\n",
    "        i = 0\n",
    "        for MSE in MSE_list:\n",
    "            MSE_x = MSE.T[0].cpu().numpy()\n",
    "            MSE_xv = MSE.T[1].cpu().numpy()\n",
    "            MSE_y = MSE.T[2].cpu().numpy()\n",
    "            MSE_yv = MSE.T[3].cpu().numpy()\n",
    "\n",
    "            MSE_combined_plot[0][0].plot(t, MSE_x, label = legend_list[i])\n",
    "            #MSE_combined_plot[0][0].legend([legend_list[i]])\n",
    "            \n",
    "            MSE_combined_plot[1][0].plot(t, MSE_y, label = legend_list[i])\n",
    "            #MSE_combined_plot[1][0].legend([legend_list[i]])\n",
    "            \n",
    "            MSE_combined_plot[0][1].plot(t, MSE_xv, label = legend_list[i])\n",
    "            #MSE_combined_plot[0][1].legend([legend_list[i]])\n",
    "            \n",
    "            MSE_combined_plot[1][1].plot(t, MSE_yv, label = legend_list[i])\n",
    "            #MSE_combined_plot[1][1].legend([legend_list[i]])\n",
    "            i += 1\n",
    "\n",
    "        MSE_combined_plot[0][0].legend(legend_list)\n",
    "        MSE_combined_plot[1][0].legend(legend_list)\n",
    "        MSE_combined_plot[0][1].legend(legend_list)\n",
    "        MSE_combined_plot[1][1].legend(legend_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f94768-f665-41b0-b070-ef71c7b88985",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = plotter()\n",
    "mse_list = [UniRNN_testing_MSE, BiRNN_testing_MSE, UniLSTM_testing_MSE, BiLSTM_testing_MSE, Transformer_testing_MSE]\n",
    "legend_list = ['Unidirectional RNN', 'Bidirectional RNN', 'Unidirectional LSTM', 'Bidirectional LSTM', 'Transformer']\n",
    "plotter.two_by_one_MSE_vs_time(mse_list, legend_list)\n",
    "plotter.two_by_two_MSE_vs_time(mse_list, legend_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fd891-f007-4f65-868a-b085e5d40ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class track_simulator():\n",
    "    def __init__(self, predictor, updater, dataloader, time_span):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_model : :class:`~.Predictor`\n",
    "            The Stone Soup predictor to be used.\n",
    "        measurement_model : :class:`~.Predictor`\n",
    "            The Updater to be used.\n",
    "        \"\"\"\n",
    "        self.predictor = predictor\n",
    "        self.updater = updater\n",
    "        self.dataloader = dataloader\n",
    "        self.time_span = time_span\n",
    "\n",
    "    def initializer(self, time_stamp, labels):\n",
    "        state_range_min = labels[0][0].cpu().numpy()\n",
    "        state_range_max = labels[0][1].cpu().numpy()\n",
    "        state_vector = StateVector(np.random.uniform(low=state_range_min, high=state_range_max))\n",
    "        return GaussianState(state_vector = state_vector, covar = np.eye(4), timestamp=time_stamp)\n",
    "\n",
    "    def _simulate_track(self, input, labels):\n",
    "        track = Track()\n",
    "        prior = self.initializer(self.time_span[0], labels)\n",
    "        for i in range(inputs.shape[1]):\n",
    "            measurement = Detection(state_vector=input[0,i].cpu().numpy(), timestamp = self.time_span[i])\n",
    "            prediction = self.predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "            posterior = self.updater.update(SingleHypothesis(prediction, measurement))\n",
    "            track.append(posterior)\n",
    "            prior = track[-1]\n",
    "        tk = np.array([e.state_vector for e in track]).squeeze().T\n",
    "        tk = torch.tensor(tk.astype(dtype=np.float32),device = device)\n",
    "        return tk.T\n",
    "\n",
    "    def generate_MSE(self):\n",
    "        avg_loss = nn.MSELoss()\n",
    "        trajectory_MSE = nn.MSELoss(reduction='none')\n",
    "        MSE = torch.zeros(1,tMax,4, device=device) # Make this auto detect it\n",
    "        test_loss=0\n",
    "        i = 0\n",
    "        for j, data in enumerate(self.dataloader):\n",
    "            inputs, labels = data\n",
    "            outputs = self._simulate_track(inputs, labels)\n",
    "            test_loss += avg_loss(outputs, labels.squeeze())\n",
    "            MSE += trajectory_MSE(outputs, labels.squeeze())\n",
    "            i += 1\n",
    "        return test_loss / i, MSE.squeeze()/len(self.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf290af-e5c2-45e5-9fce-df06c7278e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictor = ExtendedKalmanPredictor(transition_model)\n",
    "updater = ExtendedKalmanUpdater(measurement_model)\n",
    "\n",
    "track_simulator = track_simulator(predictor, updater, testloader, time_span)\n",
    "\n",
    "EKF_epoch_loss, EKF_track = track_simulator.generate_MSE()\n",
    "\n",
    "track_simulator.generate_MSE()\n",
    "\n",
    "epoch_mse, EKF_MSE = track_simulator.generate_MSE()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2359d6-d880-48ab-baf9-2138c7074505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, EKF_mse_plot = plt.subplots(2,2)\n",
    "\n",
    "EKF_x = EKF_MSE.T[0].cpu().numpy()\n",
    "EKF_xv = EKF_MSE.T[1].cpu().numpy()\n",
    "EKF_y = EKF_MSE.T[2].cpu().numpy()\n",
    "EKF_yv = EKF_MSE.T[3].cpu().numpy()\n",
    "t = range(len(time_span))\n",
    "\n",
    "fig.tight_layout()\n",
    "EKF_mse_plot[0][0].plot(t, EKF_x, color=\"C0\")\n",
    "EKF_mse_plot[0][1].plot(t, EKF_xv, color=\"C1\")\n",
    "EKF_mse_plot[1][0].plot(t, EKF_y, color=\"C2\")\n",
    "EKF_mse_plot[1][1].plot(t, EKF_yv, color=\"C3\")\n",
    "#EKFmse[1].set_title(\"Testing Loss (MSE)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1edba1-ff3d-47e5-8e56-4244b785c21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54a1f9-b8a1-4321-bee5-8163941625fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea537b1d-fe3c-4c42-b226-8c7ce8c6c27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
